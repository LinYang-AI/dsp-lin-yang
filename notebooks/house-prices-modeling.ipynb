{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Av9bFpD7tRhV"
      },
      "outputs": [],
      "source": [
        "# install category-encoders if not installed\n",
        "# !pip install category-encoders\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJVgxZxBuilN"
      },
      "source": [
        "# Import data and split feature and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "yKjs_K1Auh21",
        "outputId": "ed28b218-e195-4a06-93c2-70a6ede35aea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-811cd769-8e59-41f7-b3e3-f58cdb0c9158\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-811cd769-8e59-41f7-b3e3-f58cdb0c9158')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-811cd769-8e59-41f7-b3e3-f58cdb0c9158 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-811cd769-8e59-41f7-b3e3-f58cdb0c9158');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('./data/train.csv')\n",
        "col_drop = df.columns[df.nunique()==1]\n",
        "df.drop(col_drop, axis=1, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separate the features from the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "UdMZAF_J4Awh",
        "outputId": "f699fd92-6ef4-4ba8-c582-086e4dd2a590"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f78bd511-e5d6-4a5a-8e2d-4a55a5c32d35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 80 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f78bd511-e5d6-4a5a-8e2d-4a55a5c32d35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f78bd511-e5d6-4a5a-8e2d-4a55a5c32d35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f78bd511-e5d6-4a5a-8e2d-4a55a5c32d35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
              "0         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "1         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "2         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "3         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "4         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "\n",
              "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
              "0       0      2    2008        WD         Normal  \n",
              "1       0      5    2007        WD         Normal  \n",
              "2       0      9    2008        WD         Normal  \n",
              "3       0      2    2006        WD        Abnorml  \n",
              "4       0     12    2008        WD         Normal  \n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xtrain = df.copy()\n",
        "ytrain = Xtrain.loc[:,['SalePrice']]\n",
        "Xtrain = Xtrain.drop('SalePrice', axis = 1)\n",
        "Xtrain.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Separete the train, validation, and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "hG6y6A0ivBYu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split train and validation dataset\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(Xtrain, ytrain, test_size = 0.2, random_state = 42)\n",
        "Xval, Xtest, yval, ytest = train_test_split(Xtest, ytest, test_size = 0.5, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCFJWDMFxdzl"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separete categorical features and numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "M4zd31rs9g8k"
      },
      "outputs": [],
      "source": [
        "# get the binary categorical colums\n",
        "bin_cols = Xtrain.select_dtypes(include=['object']).columns[Xtrain.select_dtypes(include=['object']).nunique() == 2].tolist()\n",
        "# get the rest categorical columns\n",
        "ord_cols = [col for col in Xtrain.columns if col not in bin_cols and Xtrain[col].dtype == 'object']\n",
        "# get the numerical categorical columns\n",
        "num_cols = Xtrain.select_dtypes(include=['int64', 'float64']).columns\n",
        "# ensure the numerical columns have only numerical values\n",
        "Xtrain[num_cols] = Xtrain[num_cols].apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create encoder instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "vHykA9QtvFt0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
        "import category_encoders as ce\n",
        "\n",
        "\n",
        "std = StandardScaler()\n",
        "cte = ce.CountEncoder(cols=ord_cols, normalize=True, handle_unknown='value')\n",
        "ohe = ce.OneHotEncoder(cols=bin_cols, use_cat_names=False, handle_unknown='value')\n",
        "be = ce.BinaryEncoder(cols=bin_cols)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encode the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "HxJRPeymawnT"
      },
      "outputs": [],
      "source": [
        "# encode the price with StandardScaler\n",
        "std_label = StandardScaler()\n",
        "ytrain_encoded = pd.DataFrame(std_label.fit_transform(ytrain), columns=ytrain.columns)\n",
        "yval_encoded = pd.DataFrame(std_label.transform(yval), columns = yval.columns)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encode the features of train, test and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "GWPN9esA6BO9"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# encoding the features\n",
        "# one-hot encoding the binary features\n",
        "Xtrain_encoded = ohe.fit_transform(Xtrain)\n",
        "Xval_encoded = ohe.transform(Xval)\n",
        "Xtest_encoded = ohe.transform(Xtest)\n",
        "\n",
        "Xtrain_encoded = cte.fit_transform(Xtrain_encoded)\n",
        "Xval_encoded = cte.transform(Xval_encoded)\n",
        "Xtest_encoded = cte.transform(Xtest_encoded)\n",
        "\n",
        "Xtrain_scaled = std.fit_transform(Xtrain_encoded[num_cols])\n",
        "Xtrain_encoded[num_cols] = Xtrain_scaled\n",
        "Xval_scaled = std.transform(Xval_encoded[num_cols])\n",
        "Xval_encoded[num_cols] = Xval_scaled\n",
        "Xtest_scaled = std.transform(Xtest_encoded[num_cols])\n",
        "Xtest_encoded[num_cols] = Xtest_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Eo2YWheWWsaL",
        "outputId": "9ffa7514-65c0-4d0a-a0bf-b70e0651742b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1df358f0-cf63-4b44-8ae1-93819df2db81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street_1</th>\n",
              "      <th>Street_2</th>\n",
              "      <th>Alley_1</th>\n",
              "      <th>Alley_2</th>\n",
              "      <th>Alley_3</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>-1.119284</td>\n",
              "      <td>-0.866764</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>-0.013818</td>\n",
              "      <td>-0.212896</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.275838</td>\n",
              "      <td>-0.070993</td>\n",
              "      <td>0.994863</td>\n",
              "      <td>0.800514</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>-0.09274</td>\n",
              "      <td>-0.133417</td>\n",
              "      <td>1.650065</td>\n",
              "      <td>0.866438</td>\n",
              "      <td>0.825342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1066</th>\n",
              "      <td>0.790464</td>\n",
              "      <td>0.074110</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>-0.455871</td>\n",
              "      <td>-0.265245</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.275838</td>\n",
              "      <td>-0.070993</td>\n",
              "      <td>0.994863</td>\n",
              "      <td>0.800514</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>-0.09274</td>\n",
              "      <td>-0.508010</td>\n",
              "      <td>0.893677</td>\n",
              "      <td>0.866438</td>\n",
              "      <td>0.825342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>-0.216152</td>\n",
              "      <td>-0.631546</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>-0.134378</td>\n",
              "      <td>-0.177841</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.275838</td>\n",
              "      <td>-0.070993</td>\n",
              "      <td>0.994863</td>\n",
              "      <td>0.109589</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>-0.09274</td>\n",
              "      <td>-0.508010</td>\n",
              "      <td>0.137290</td>\n",
              "      <td>0.866438</td>\n",
              "      <td>0.825342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>0.162505</td>\n",
              "      <td>-0.161109</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>-0.415684</td>\n",
              "      <td>-0.324474</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.275838</td>\n",
              "      <td>-0.070993</td>\n",
              "      <td>0.994863</td>\n",
              "      <td>0.109589</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>-0.09274</td>\n",
              "      <td>-0.133417</td>\n",
              "      <td>-0.619098</td>\n",
              "      <td>0.866438</td>\n",
              "      <td>0.825342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>-0.822944</td>\n",
              "      <td>-0.161109</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>-0.817550</td>\n",
              "      <td>-0.529035</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.275838</td>\n",
              "      <td>-0.070993</td>\n",
              "      <td>0.994863</td>\n",
              "      <td>0.800514</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>-0.09274</td>\n",
              "      <td>-0.508010</td>\n",
              "      <td>1.650065</td>\n",
              "      <td>0.866438</td>\n",
              "      <td>0.825342</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 85 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1df358f0-cf63-4b44-8ae1-93819df2db81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1df358f0-cf63-4b44-8ae1-93819df2db81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1df358f0-cf63-4b44-8ae1-93819df2db81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Id  MSSubClass  MSZoning  LotFrontage   LotArea  Street_1  \\\n",
              "254  -1.119284   -0.866764  0.791096    -0.013818 -0.212896         1   \n",
              "1066  0.790464    0.074110  0.791096    -0.455871 -0.265245         1   \n",
              "638  -0.216152   -0.631546  0.791096    -0.134378 -0.177841         1   \n",
              "799   0.162505   -0.161109  0.791096    -0.415684 -0.324474         1   \n",
              "380  -0.822944   -0.161109  0.791096    -0.817550 -0.529035         1   \n",
              "\n",
              "      Street_2  Alley_1  Alley_2  Alley_3  ...  ScreenPorch  PoolArea  \\\n",
              "254          0        1        0        0  ...    -0.275838 -0.070993   \n",
              "1066         0        1        0        0  ...    -0.275838 -0.070993   \n",
              "638          0        1        0        0  ...    -0.275838 -0.070993   \n",
              "799          0        1        0        0  ...    -0.275838 -0.070993   \n",
              "380          0        0        1        0  ...    -0.275838 -0.070993   \n",
              "\n",
              "        PoolQC     Fence  MiscFeature  MiscVal    MoSold    YrSold  SaleType  \\\n",
              "254   0.994863  0.800514     0.960616 -0.09274 -0.133417  1.650065  0.866438   \n",
              "1066  0.994863  0.800514     0.960616 -0.09274 -0.508010  0.893677  0.866438   \n",
              "638   0.994863  0.109589     0.960616 -0.09274 -0.508010  0.137290  0.866438   \n",
              "799   0.994863  0.109589     0.960616 -0.09274 -0.133417 -0.619098  0.866438   \n",
              "380   0.994863  0.800514     0.960616 -0.09274 -0.508010  1.650065  0.866438   \n",
              "\n",
              "      SaleCondition  \n",
              "254        0.825342  \n",
              "1066       0.825342  \n",
              "638        0.825342  \n",
              "799        0.825342  \n",
              "380        0.825342  \n",
              "\n",
              "[5 rows x 85 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xtrain_encoded.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7AuuLRBqyEcL"
      },
      "source": [
        "# Feature Projection\n",
        "This step is for reducing the number of features to keep features that are important."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PCA projection\n",
        "There are many ways to do feature selection, here I'll use PCA method.\n",
        "\n",
        "To be able to apply PCA to reduce the dimension, we need to ensure there are no 'nan' existing in the dataset\n",
        "\n",
        "To ensure non 'nan' presenting in the datasets, I replace value 'nan' with 0 in features. (This can also be resolved by replacing 'nan' with mean or median)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "36-hwTuXzn2i"
      },
      "outputs": [],
      "source": [
        "Xtrain_encoded = Xtrain_encoded.fillna(0)\n",
        "Xval_encoded = Xval_encoded.fillna(0)\n",
        "Xtest_encoded = Xtest_encoded.fillna(0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### PCA features projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "X2S7rmxwxtFM"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(None)\n",
        "Xtrain_pca = pca.fit_transform(Xtrain_encoded)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To determine which features are kept, we need to know the importance of each feature.\n",
        "We can take account of the proportion of variance in the original (encoded) data that is explained by each principal component of the PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpbut3Ug60BS",
        "outputId": "2a19348e-75dc-4e74-a27d-eda8c2bb0813"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['18.30%',\n",
              " '8.53%',\n",
              " '6.82%',\n",
              " '5.20%',\n",
              " '3.95%',\n",
              " '3.15%',\n",
              " '3.05%',\n",
              " '2.97%',\n",
              " '2.95%',\n",
              " '2.85%',\n",
              " '2.78%',\n",
              " '2.68%',\n",
              " '2.63%',\n",
              " '2.60%',\n",
              " '2.55%',\n",
              " '2.37%',\n",
              " '2.27%',\n",
              " '2.14%',\n",
              " '2.09%',\n",
              " '2.00%',\n",
              " '1.90%',\n",
              " '1.72%',\n",
              " '1.61%',\n",
              " '1.48%',\n",
              " '1.33%',\n",
              " '1.09%',\n",
              " '1.02%',\n",
              " '0.87%',\n",
              " '0.75%',\n",
              " '0.69%',\n",
              " '0.62%',\n",
              " '0.53%',\n",
              " '0.42%',\n",
              " '0.35%',\n",
              " '0.30%',\n",
              " '0.27%',\n",
              " '0.23%',\n",
              " '0.22%',\n",
              " '0.19%',\n",
              " '0.18%',\n",
              " '0.17%',\n",
              " '0.17%',\n",
              " '0.17%',\n",
              " '0.15%',\n",
              " '0.14%',\n",
              " '0.13%',\n",
              " '0.12%',\n",
              " '0.12%',\n",
              " '0.11%',\n",
              " '0.10%',\n",
              " '0.10%',\n",
              " '0.07%',\n",
              " '0.07%',\n",
              " '0.07%',\n",
              " '0.06%',\n",
              " '0.06%',\n",
              " '0.05%',\n",
              " '0.05%',\n",
              " '0.05%',\n",
              " '0.05%',\n",
              " '0.04%',\n",
              " '0.04%',\n",
              " '0.04%',\n",
              " '0.03%',\n",
              " '0.03%',\n",
              " '0.03%',\n",
              " '0.02%',\n",
              " '0.02%',\n",
              " '0.02%',\n",
              " '0.02%',\n",
              " '0.02%',\n",
              " '0.01%',\n",
              " '0.01%',\n",
              " '0.01%',\n",
              " '0.01%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%']"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "variances = [f\"{comp:.2%}\" for comp in pca.explained_variance_ratio_]\n",
        "variances"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize the cumulative sum of the explained variance ratio as a function of the number of components to help us to determine the remained number of components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "3YbmCzsM7IC6",
        "outputId": "8a48a959-693d-40b6-eee2-68b7254ac40c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(range(1, len(pca.explained_variance_ratio_)+1), np.cumsum(pca.explained_variance_ratio_ * 100))\n",
        "plt.xlabel(\"Number of components\", fontsize=16)\n",
        "plt.ylabel(\"Explained variance (%)\", fontsize = 16)\n",
        "plt.tick_params(labelsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Feature Projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "V_Oqv88874xC"
      },
      "outputs": [],
      "source": [
        "# Select 20 principal components with highest explained variance as seen above\n",
        "# change the number of principal components to optimize model\n",
        "explained_variances = pca.explained_variance_ratio_\n",
        "selected_pca_indices = explained_variances.argsort()[::-1][:27]\n",
        "Xtrain_pca_selected = Xtrain_pca[:, selected_pca_indices]\n",
        "\n",
        "# create new train, validation, and test datasets with selected features\n",
        "Xtrain_selected = Xtrain_encoded.iloc[:, selected_pca_indices]\n",
        "Xval_selected = Xval_encoded.iloc[:, selected_pca_indices]\n",
        "Xtest_selected = Xtest_encoded.iloc[:, selected_pca_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TQACpi6WLKc"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8STXPBh0WQGT"
      },
      "source": [
        "#### Suppose there is a linear relationship between the house price and the features\n",
        "We can implement non-linear regression in the model during optimization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "SW30DH8KP-Zj"
      },
      "outputs": [],
      "source": [
        "def reset_seeds():\n",
        "    os.environ['PYTHONHASHSEED']=str(2)\n",
        "    tf.random.set_seed(2)\n",
        "    np.random.seed(2)\n",
        "    random.seed(2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create the model with TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "PuBvBrbCYCCT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "reset_seeds()\n",
        "\n",
        "def polynomial_activation(x):\n",
        "  return tf.keras.backend.square(x)\n",
        "\n",
        "n_features = Xtrain_selected.shape[1]\n",
        "input = Input(shape=(n_features,))\n",
        "#dropout1 = Dropout(0.5)(input)\n",
        "hidden1 = Dense(units = n_features, \n",
        "                activation = polynomial_activation, \n",
        "                activity_regularizer = tf.keras.regularizers.L2(0.01))(input)\n",
        "#dropout2 = Dropout(0.5)(hidden1)\n",
        "hidden2 = Dense(units = n_features//2, \n",
        "                activation = 'linear',\n",
        "                activity_regularizer = tf.keras.regularizers.L2(0.01))(hidden1)\n",
        "hidden3 = Dense(units = n_features//4, \n",
        "                activation = 'linear',\n",
        "                activity_regularizer = tf.keras.regularizers.L2(0.01))(hidden2)\n",
        "hidden4 = Dense(units = n_features//4, \n",
        "                activation = polynomial_activation,\n",
        "                activity_regularizer = tf.keras.regularizers.L2(0.01))(hidden3)\n",
        "output = Dense(units=1, activation = 'linear')(hidden2)\n",
        "\n",
        "house = Model(inputs=input, outputs = output)\n",
        "house.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005, use_ema=True, ema_momentum=0.99), loss=tf.keras.losses.MSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq0T4bjMagma",
        "outputId": "c6ee6c39-bd18-480b-f4dd-f1a91e07f91e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 27)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 27)                756       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13)                364       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 14        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,134\n",
            "Trainable params: 1,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "house.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "GpgaQ86-aiC5",
        "outputId": "bf80151b-df15-4d5a-b7a5-71d281f040f3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.plot_model(house, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDmNeG33dRJD"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlncD9f1amQa",
        "outputId": "bd7c49eb-805c-4474-f6a1-fe3c6a8c622c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 15ms/step - loss: 5.0514 - val_loss: 1.6843\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9354 - val_loss: 1.3107\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1171 - val_loss: 1.1642\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7925 - val_loss: 1.0701\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5734 - val_loss: 0.9914\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4462 - val_loss: 0.9136\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3487 - val_loss: 0.8442\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2689 - val_loss: 0.7886\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1996 - val_loss: 0.7393\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1447 - val_loss: 0.6942\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0878 - val_loss: 0.6629\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0418 - val_loss: 0.6317\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0020 - val_loss: 0.6057\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9643 - val_loss: 0.5782\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9315 - val_loss: 0.5545\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9002 - val_loss: 0.5330\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8728 - val_loss: 0.5146\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8476 - val_loss: 0.4965\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8239 - val_loss: 0.4823\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8022 - val_loss: 0.4652\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7822 - val_loss: 0.4519\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7632 - val_loss: 0.4387\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7450 - val_loss: 0.4259\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7282 - val_loss: 0.4143\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7141 - val_loss: 0.4022\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6978 - val_loss: 0.3917\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6838 - val_loss: 0.3820\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6706 - val_loss: 0.3707\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.6579 - val_loss: 0.3634\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6457 - val_loss: 0.3568\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6367 - val_loss: 0.3501\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6254 - val_loss: 0.3440\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6136 - val_loss: 0.3345\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6033 - val_loss: 0.3282\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5936 - val_loss: 0.3212\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5849 - val_loss: 0.3160\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5763 - val_loss: 0.3097\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.5672 - val_loss: 0.3058\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5584 - val_loss: 0.2993\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.5519 - val_loss: 0.2935\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5431 - val_loss: 0.2897\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5369 - val_loss: 0.2858\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5308 - val_loss: 0.2815\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5222 - val_loss: 0.2771\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5166 - val_loss: 0.2720\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5098 - val_loss: 0.2710\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5027 - val_loss: 0.2664\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4967 - val_loss: 0.2630\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4922 - val_loss: 0.2590\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4854 - val_loss: 0.2565\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4803 - val_loss: 0.2534\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4744 - val_loss: 0.2508\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4687 - val_loss: 0.2480\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4638 - val_loss: 0.2444\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4587 - val_loss: 0.2429\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4545 - val_loss: 0.2395\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4490 - val_loss: 0.2376\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4446 - val_loss: 0.2363\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4411 - val_loss: 0.2331\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4356 - val_loss: 0.2295\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4305 - val_loss: 0.2308\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4252 - val_loss: 0.2273\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4221 - val_loss: 0.2250\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4166 - val_loss: 0.2239\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4123 - val_loss: 0.2215\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4080 - val_loss: 0.2213\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.4046 - val_loss: 0.2206\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4014 - val_loss: 0.2176\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3974 - val_loss: 0.2189\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3919 - val_loss: 0.2141\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3892 - val_loss: 0.2115\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3856 - val_loss: 0.2130\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3820 - val_loss: 0.2107\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3813 - val_loss: 0.2098\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3773 - val_loss: 0.2110\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3744 - val_loss: 0.2077\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3726 - val_loss: 0.2074\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3682 - val_loss: 0.2049\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3646 - val_loss: 0.2035\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3634 - val_loss: 0.2044\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3601 - val_loss: 0.2014\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3578 - val_loss: 0.2020\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3575 - val_loss: 0.1998\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3549 - val_loss: 0.1985\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3507 - val_loss: 0.1991\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3485 - val_loss: 0.1976\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3460 - val_loss: 0.1974\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3436 - val_loss: 0.1958\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3411 - val_loss: 0.1953\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3406 - val_loss: 0.1937\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3381 - val_loss: 0.1931\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3348 - val_loss: 0.1934\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3339 - val_loss: 0.1911\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3316 - val_loss: 0.1933\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3317 - val_loss: 0.1926\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3287 - val_loss: 0.1921\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3262 - val_loss: 0.1889\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3242 - val_loss: 0.1900\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3220 - val_loss: 0.1879\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3206 - val_loss: 0.1898\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3208 - val_loss: 0.1882\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3170 - val_loss: 0.1856\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3154 - val_loss: 0.1893\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3162 - val_loss: 0.1880\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3139 - val_loss: 0.1855\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3183 - val_loss: 0.1889\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3083 - val_loss: 0.1837\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3059 - val_loss: 0.1885\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3049 - val_loss: 0.1838\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3038 - val_loss: 0.1850\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3012 - val_loss: 0.1845\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.1832\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2998 - val_loss: 0.1824\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2971 - val_loss: 0.1847\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2961 - val_loss: 0.1844\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2943 - val_loss: 0.1819\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2952 - val_loss: 0.1841\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2923 - val_loss: 0.1820\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2907 - val_loss: 0.1835\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2891 - val_loss: 0.1840\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2882 - val_loss: 0.1814\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2881 - val_loss: 0.1828\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2860 - val_loss: 0.1823\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2840 - val_loss: 0.1813\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2849 - val_loss: 0.1831\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2821 - val_loss: 0.1816\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2813 - val_loss: 0.1850\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2808 - val_loss: 0.1792\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2790 - val_loss: 0.1828\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2780 - val_loss: 0.1825\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2761 - val_loss: 0.1823\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2749 - val_loss: 0.1800\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2741 - val_loss: 0.1800\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2738 - val_loss: 0.1785\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2724 - val_loss: 0.1804\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2704 - val_loss: 0.1778\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2717 - val_loss: 0.1805\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2694 - val_loss: 0.1810\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2688 - val_loss: 0.1800\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2689 - val_loss: 0.1810\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2660 - val_loss: 0.1798\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2652 - val_loss: 0.1815\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2640 - val_loss: 0.1793\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2630 - val_loss: 0.1815\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2627 - val_loss: 0.1819\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2619 - val_loss: 0.1789\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2596 - val_loss: 0.1824\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2593 - val_loss: 0.1814\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2586 - val_loss: 0.1798\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2579 - val_loss: 0.1808\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2568 - val_loss: 0.1798\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2563 - val_loss: 0.1828\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2558 - val_loss: 0.1780\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2538 - val_loss: 0.1845\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2539 - val_loss: 0.1796\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2531 - val_loss: 0.1838\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2541 - val_loss: 0.1797\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2525 - val_loss: 0.1830\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2507 - val_loss: 0.1807\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2495 - val_loss: 0.1800\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2493 - val_loss: 0.1776\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2482 - val_loss: 0.1808\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2473 - val_loss: 0.1815\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2469 - val_loss: 0.1791\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2459 - val_loss: 0.1829\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2460 - val_loss: 0.1800\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2456 - val_loss: 0.1832\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2438 - val_loss: 0.1778\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2447 - val_loss: 0.1809\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2444 - val_loss: 0.1821\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2430 - val_loss: 0.1818\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2414 - val_loss: 0.1797\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2407 - val_loss: 0.1831\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2410 - val_loss: 0.1805\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2395 - val_loss: 0.1798\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2396 - val_loss: 0.1838\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2388 - val_loss: 0.1812\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2371 - val_loss: 0.1785\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2366 - val_loss: 0.1818\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2389 - val_loss: 0.1813\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2363 - val_loss: 0.1795\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2349 - val_loss: 0.1869\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2350 - val_loss: 0.1798\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2348 - val_loss: 0.1841\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2328 - val_loss: 0.1789\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2344 - val_loss: 0.1794\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2334 - val_loss: 0.1805\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2311 - val_loss: 0.1823\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2337 - val_loss: 0.1808\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2312 - val_loss: 0.1804\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2311 - val_loss: 0.1792\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2299 - val_loss: 0.1814\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2294 - val_loss: 0.1824\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2290 - val_loss: 0.1802\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2280 - val_loss: 0.1814\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2270 - val_loss: 0.1836\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2276 - val_loss: 0.1804\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.1830\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2264 - val_loss: 0.1802\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2278 - val_loss: 0.1882\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2248 - val_loss: 0.1808\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2255 - val_loss: 0.1795\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2237 - val_loss: 0.1850\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2234 - val_loss: 0.1840\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2251 - val_loss: 0.1882\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2237 - val_loss: 0.1796\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2229 - val_loss: 0.1844\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2221 - val_loss: 0.1813\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2210 - val_loss: 0.1795\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2213 - val_loss: 0.1831\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2200 - val_loss: 0.1791\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2199 - val_loss: 0.1808\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2204 - val_loss: 0.1821\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2214 - val_loss: 0.1826\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2189 - val_loss: 0.1852\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2186 - val_loss: 0.1812\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2189 - val_loss: 0.1878\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2266 - val_loss: 0.1798\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2216 - val_loss: 0.1908\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2170 - val_loss: 0.1844\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2164 - val_loss: 0.1835\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2153 - val_loss: 0.1810\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2155 - val_loss: 0.1826\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2158 - val_loss: 0.1850\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2168 - val_loss: 0.1820\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2151 - val_loss: 0.1826\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2134 - val_loss: 0.1843\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2140 - val_loss: 0.1828\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2134 - val_loss: 0.1848\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2136 - val_loss: 0.1831\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2123 - val_loss: 0.1829\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2121 - val_loss: 0.1845\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2121 - val_loss: 0.1827\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2111 - val_loss: 0.1814\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2116 - val_loss: 0.1852\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2107 - val_loss: 0.1805\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2107 - val_loss: 0.1837\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2097 - val_loss: 0.1838\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2101 - val_loss: 0.1900\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2092 - val_loss: 0.1836\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2091 - val_loss: 0.1863\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2097 - val_loss: 0.1859\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2087 - val_loss: 0.1862\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2089 - val_loss: 0.1842\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2102 - val_loss: 0.1868\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2090 - val_loss: 0.1886\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2072 - val_loss: 0.1824\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2066 - val_loss: 0.1868\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2070 - val_loss: 0.1853\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2071 - val_loss: 0.1865\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2072 - val_loss: 0.1856\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2070 - val_loss: 0.1833\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2047 - val_loss: 0.1856\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2060 - val_loss: 0.1873\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2065 - val_loss: 0.1812\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2062 - val_loss: 0.1875\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2052 - val_loss: 0.1840\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2073 - val_loss: 0.1918\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2036 - val_loss: 0.1840\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2038 - val_loss: 0.1881\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2038 - val_loss: 0.1893\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2044 - val_loss: 0.1902\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2020 - val_loss: 0.1841\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2051 - val_loss: 0.1891\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2014 - val_loss: 0.1812\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2021 - val_loss: 0.1880\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2014 - val_loss: 0.1839\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2011 - val_loss: 0.1877\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2015 - val_loss: 0.1904\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2031 - val_loss: 0.1842\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2030 - val_loss: 0.1912\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2067 - val_loss: 0.1821\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2023 - val_loss: 0.1868\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.1854\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2002 - val_loss: 0.1858\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2026 - val_loss: 0.1898\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2055 - val_loss: 0.1830\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2040 - val_loss: 0.1891\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1980 - val_loss: 0.1853\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1974 - val_loss: 0.1865\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1986 - val_loss: 0.1885\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1989 - val_loss: 0.1875\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1974 - val_loss: 0.1844\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1971 - val_loss: 0.1853\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1974 - val_loss: 0.1854\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1977 - val_loss: 0.1894\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1974 - val_loss: 0.1868\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1972 - val_loss: 0.1849\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1950 - val_loss: 0.1909\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1965 - val_loss: 0.1933\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1958 - val_loss: 0.1902\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1963 - val_loss: 0.1830\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1949 - val_loss: 0.1877\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1951 - val_loss: 0.1866\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1950 - val_loss: 0.1896\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2018 - val_loss: 0.1969\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1970 - val_loss: 0.1896\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1943 - val_loss: 0.1903\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1933 - val_loss: 0.1933\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1953 - val_loss: 0.1871\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1950 - val_loss: 0.1912\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1960 - val_loss: 0.1939\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1947 - val_loss: 0.1915\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1937 - val_loss: 0.1916\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1949 - val_loss: 0.1899\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1932 - val_loss: 0.1946\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1935 - val_loss: 0.1836\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1954 - val_loss: 0.1940\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2011 - val_loss: 0.1933\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1977 - val_loss: 0.1897\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1927 - val_loss: 0.1930\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1957 - val_loss: 0.1912\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1925 - val_loss: 0.1878\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1909 - val_loss: 0.1915\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1900 - val_loss: 0.1916\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1906 - val_loss: 0.1869\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1914 - val_loss: 0.1959\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1906 - val_loss: 0.1903\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1913 - val_loss: 0.1863\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1901 - val_loss: 0.1905\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1898 - val_loss: 0.1935\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1899 - val_loss: 0.1897\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1892 - val_loss: 0.1894\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1900 - val_loss: 0.1918\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1888 - val_loss: 0.1889\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1919 - val_loss: 0.2001\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1910 - val_loss: 0.1971\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1899 - val_loss: 0.1887\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1894 - val_loss: 0.1963\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1881 - val_loss: 0.1922\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.1880 - val_loss: 0.1921\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.1876 - val_loss: 0.1933\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.1882 - val_loss: 0.1966\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1891 - val_loss: 0.1907\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1892 - val_loss: 0.1909\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1900 - val_loss: 0.1931\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1899 - val_loss: 0.1910\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1899 - val_loss: 0.1919\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1883 - val_loss: 0.1898\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1871 - val_loss: 0.1977\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1871 - val_loss: 0.1910\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1886 - val_loss: 0.1957\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1883 - val_loss: 0.1936\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1904 - val_loss: 0.1923\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1894 - val_loss: 0.1877\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1895 - val_loss: 0.1937\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1853 - val_loss: 0.1886\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1874 - val_loss: 0.1892\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1848 - val_loss: 0.1984\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1866 - val_loss: 0.1875\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1857 - val_loss: 0.2023\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1864 - val_loss: 0.1914\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1872 - val_loss: 0.1983\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1871 - val_loss: 0.1891\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1885 - val_loss: 0.1938\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1864 - val_loss: 0.1941\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1870 - val_loss: 0.1959\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1885 - val_loss: 0.1963\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1885 - val_loss: 0.1954\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2039 - val_loss: 0.1910\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1893 - val_loss: 0.1946\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1845 - val_loss: 0.1923\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1834 - val_loss: 0.1978\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1848 - val_loss: 0.1958\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1838 - val_loss: 0.1917\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1839 - val_loss: 0.1920\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1828 - val_loss: 0.1962\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1820 - val_loss: 0.1951\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1834 - val_loss: 0.1995\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1819 - val_loss: 0.1955\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1828 - val_loss: 0.1963\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1827 - val_loss: 0.2013\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1827 - val_loss: 0.1954\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1853 - val_loss: 0.1920\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1845 - val_loss: 0.2013\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1825 - val_loss: 0.1952\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1847 - val_loss: 0.1946\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2109 - val_loss: 0.1915\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1886 - val_loss: 0.1952\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1828 - val_loss: 0.1980\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1817 - val_loss: 0.1945\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1805 - val_loss: 0.1965\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1807 - val_loss: 0.1962\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1823 - val_loss: 0.1927\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1810 - val_loss: 0.1990\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1865 - val_loss: 0.1929\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1838 - val_loss: 0.1933\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1824 - val_loss: 0.1990\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1810 - val_loss: 0.1935\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1802 - val_loss: 0.1947\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1805 - val_loss: 0.2030\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1808 - val_loss: 0.1991\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1807 - val_loss: 0.2040\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1797 - val_loss: 0.1957\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1853 - val_loss: 0.2078\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1793 - val_loss: 0.1969\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1792 - val_loss: 0.2119\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1811 - val_loss: 0.1994\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1805 - val_loss: 0.1989\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1817 - val_loss: 0.1935\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1857 - val_loss: 0.2111\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1793 - val_loss: 0.1968\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1798 - val_loss: 0.1963\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1798 - val_loss: 0.2017\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1787 - val_loss: 0.1938\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1802 - val_loss: 0.2010\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1803 - val_loss: 0.2056\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1798 - val_loss: 0.1972\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1782 - val_loss: 0.2028\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1782 - val_loss: 0.1955\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1789 - val_loss: 0.1993\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1780 - val_loss: 0.2026\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1777 - val_loss: 0.2043\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1777 - val_loss: 0.1982\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1770 - val_loss: 0.1982\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.1781 - val_loss: 0.2060\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.1762 - val_loss: 0.2004\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1801 - val_loss: 0.1983\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1791 - val_loss: 0.2118\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1778 - val_loss: 0.1995\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1763 - val_loss: 0.2044\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1770 - val_loss: 0.1994\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1763 - val_loss: 0.1979\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1798 - val_loss: 0.2136\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1786 - val_loss: 0.2008\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1790 - val_loss: 0.1994\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1786 - val_loss: 0.1946\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1767 - val_loss: 0.2107\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1842 - val_loss: 0.1942\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1814 - val_loss: 0.2075\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1810 - val_loss: 0.2038\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1796 - val_loss: 0.2017\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1759 - val_loss: 0.2057\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1772 - val_loss: 0.2120\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1776 - val_loss: 0.2058\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1809 - val_loss: 0.1955\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1770 - val_loss: 0.2016\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1784 - val_loss: 0.2006\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1793 - val_loss: 0.2015\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1819 - val_loss: 0.2033\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1798 - val_loss: 0.2075\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1837 - val_loss: 0.2031\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1825 - val_loss: 0.2176\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1787 - val_loss: 0.2060\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1797 - val_loss: 0.2039\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1843 - val_loss: 0.2086\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1881 - val_loss: 0.2009\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1915 - val_loss: 0.2137\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1953 - val_loss: 0.1993\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1866 - val_loss: 0.2065\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1800 - val_loss: 0.2013\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1769 - val_loss: 0.2036\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1754 - val_loss: 0.2024\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1760 - val_loss: 0.2061\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1743 - val_loss: 0.2004\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1736 - val_loss: 0.2035\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1735 - val_loss: 0.2087\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1736 - val_loss: 0.1989\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1738 - val_loss: 0.2128\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1757 - val_loss: 0.2037\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1738 - val_loss: 0.2080\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1742 - val_loss: 0.2023\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1743 - val_loss: 0.2035\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1730 - val_loss: 0.2063\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.1744 - val_loss: 0.2013\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.1736 - val_loss: 0.2018\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.1746 - val_loss: 0.2017\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.1775 - val_loss: 0.2068\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1764 - val_loss: 0.2026\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1741 - val_loss: 0.2104\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.1768 - val_loss: 0.2057\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1789 - val_loss: 0.2107\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1734 - val_loss: 0.2063\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1741 - val_loss: 0.2049\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1765 - val_loss: 0.2167\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1729 - val_loss: 0.2051\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1721 - val_loss: 0.2087\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1736 - val_loss: 0.2150\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1728 - val_loss: 0.2059\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1722 - val_loss: 0.2031\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1723 - val_loss: 0.2120\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1717 - val_loss: 0.2070\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1720 - val_loss: 0.2098\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1726 - val_loss: 0.2096\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1720 - val_loss: 0.2040\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1720 - val_loss: 0.2137\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1726 - val_loss: 0.2041\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1734 - val_loss: 0.2016\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1758 - val_loss: 0.2022\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1737 - val_loss: 0.2069\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1717 - val_loss: 0.2073\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1732 - val_loss: 0.2142\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1729 - val_loss: 0.2070\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1734 - val_loss: 0.2018\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1715 - val_loss: 0.2071\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1712 - val_loss: 0.2108\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1710 - val_loss: 0.2141\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1707 - val_loss: 0.2006\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1714 - val_loss: 0.2047\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1719 - val_loss: 0.2122\n"
          ]
        }
      ],
      "source": [
        "from keras.optimizers.schedules.learning_rate_schedule import LearningRateSchedule\n",
        "\n",
        "epoch = 500\n",
        "batch = 64\n",
        "reset_seeds()\n",
        "\n",
        "history = house.fit(Xtrain_selected, \n",
        "                    ytrain_encoded, \n",
        "                    batch_size = batch, \n",
        "                    epochs = epoch, \n",
        "                    validation_data = (Xval_selected, yval_encoded))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Let's plot the loss of the model from training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "tu3z_8Ne_RsJ",
        "outputId": "9725beea-2cee-4ff9-c95f-ae40346a8116"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss, val_loss = history.history['loss'], history.history['val_loss']\n",
        "plt.plot(loss, label=\"Training Loss\")\n",
        "plt.plot(val_loss, label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Let's evaluate the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mZVi2eUGIYY",
        "outputId": "b00118aa-2fc1-434d-cca5-bc3e570efe38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = house.predict(Xtest_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "GARozYVkGQgw"
      },
      "outputs": [],
      "source": [
        "y_hat = std_label.inverse_transform(y_pred)\n",
        "\n",
        "ytest_true = ytest['SalePrice'].values\n",
        "ytrain_true =ytrain['SalePrice'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "LgO6NAXQ_9OJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "def compute_rmsle(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
        "  rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
        "  return round(rmsle, precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs-gOzIiGq5Q",
        "outputId": "5993b3a7-f474-408b-e9dd-75beb505c934"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.21"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = compute_rmsle(ytest_true, y_hat)\n",
        "results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Discussion\n",
        "The RMSE I got is not very good. The best value I got from training is 0.18 with different parameter setup of the model and feature selection. There might be a better way to model the relationship between the features and the target variable, or I can improve the performance of the model by using a different feature projection method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
