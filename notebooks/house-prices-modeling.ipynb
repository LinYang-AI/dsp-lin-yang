{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Av9bFpD7tRhV"
      },
      "outputs": [],
      "source": [
        "# install category-encoders if not installed\n",
        "# !pip install category-encoders\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJVgxZxBuilN"
      },
      "source": [
        "# Import data and split feature and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "yKjs_K1Auh21",
        "outputId": "ed28b218-e195-4a06-93c2-70a6ede35aea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../data/house-prices-advanced-regression-techniques/train.csv')\n",
        "col_drop = df.columns[df.nunique()==1]\n",
        "df.drop(col_drop, axis=1, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separate the features from the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "UdMZAF_J4Awh",
        "outputId": "f699fd92-6ef4-4ba8-c582-086e4dd2a590"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 80 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
              "0         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "1         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "2         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "3         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "4         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
              "\n",
              "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
              "0       0      2    2008        WD         Normal  \n",
              "1       0      5    2007        WD         Normal  \n",
              "2       0      9    2008        WD         Normal  \n",
              "3       0      2    2006        WD        Abnorml  \n",
              "4       0     12    2008        WD         Normal  \n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xtrain = df.copy()\n",
        "ytrain = Xtrain.loc[:,['SalePrice']]\n",
        "Xtrain = Xtrain.drop('SalePrice', axis = 1)\n",
        "Xtrain.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Separete the train, validation, and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hG6y6A0ivBYu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split train and validation dataset\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(Xtrain, ytrain, test_size = 0.2, random_state = 42)\n",
        "Xval, Xtest, yval, ytest = train_test_split(Xtest, ytest, test_size = 0.5, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCFJWDMFxdzl"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separete categorical features and numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M4zd31rs9g8k"
      },
      "outputs": [],
      "source": [
        "# get the binary categorical colums\n",
        "bin_cols = Xtrain.select_dtypes(include=['object']).columns[Xtrain.select_dtypes(include=['object']).nunique() == 2].tolist()\n",
        "# get the rest categorical columns\n",
        "ord_cols = [col for col in Xtrain.columns if col not in bin_cols and Xtrain[col].dtype == 'object']\n",
        "# get the numerical categorical columns\n",
        "num_cols = Xtrain.select_dtypes(include=['int64', 'float64']).columns\n",
        "# ensure the numerical columns have only numerical values\n",
        "Xtrain[num_cols] = Xtrain[num_cols].apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create encoder instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vHykA9QtvFt0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
        "import category_encoders as ce\n",
        "\n",
        "\n",
        "std = StandardScaler()\n",
        "cte = ce.CountEncoder(cols=ord_cols, normalize=True, handle_unknown='value')\n",
        "ohe = ce.OneHotEncoder(cols=bin_cols, use_cat_names=False, handle_unknown='value')\n",
        "be = ce.BinaryEncoder(cols=bin_cols)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encode the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HxJRPeymawnT"
      },
      "outputs": [],
      "source": [
        "# encode the price with StandardScaler\n",
        "std_label = StandardScaler()\n",
        "ytrain_encoded = pd.DataFrame(std_label.fit_transform(ytrain), columns=ytrain.columns)\n",
        "yval_encoded = pd.DataFrame(std_label.transform(yval), columns = yval.columns)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encode the features of train, test and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GWPN9esA6BO9"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# encoding the features\n",
        "# one-hot encoding the binary features\n",
        "Xtrain_encoded = ohe.fit_transform(Xtrain)\n",
        "Xval_encoded = ohe.transform(Xval)\n",
        "Xtest_encoded = ohe.transform(Xtest)\n",
        "\n",
        "Xtrain_encoded = cte.fit_transform(Xtrain_encoded)\n",
        "Xval_encoded = cte.transform(Xval_encoded)\n",
        "Xtest_encoded = cte.transform(Xtest_encoded)\n",
        "\n",
        "Xtrain_scaled = std.fit_transform(Xtrain_encoded[num_cols])\n",
        "Xtrain_encoded[num_cols] = Xtrain_scaled\n",
        "Xval_scaled = std.transform(Xval_encoded[num_cols])\n",
        "Xval_encoded[num_cols] = Xval_scaled\n",
        "Xtest_scaled = std.transform(Xtest_encoded[num_cols])\n",
        "Xtest_encoded[num_cols] = Xtest_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Eo2YWheWWsaL",
        "outputId": "9ffa7514-65c0-4d0a-a0bf-b70e0651742b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street_1</th>\n",
              "      <th>Street_2</th>\n",
              "      <th>Alley_1</th>\n",
              "      <th>Alley_2</th>\n",
              "      <th>Alley_3</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>-1.119284</td>\n",
              "      <td>-0.866764</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>-0.013818</td>\n",
              "      <td>-0.212896</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.275838</td>\n",
              "      <td>-0.070993</td>\n",
              "      <td>0.994863</td>\n",
              "      <td>0.800514</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>-0.09274</td>\n",
              "      <td>-0.133417</td>\n",
              "      <td>1.650065</td>\n",
              "      <td>0.866438</td>\n",
              "      <td>0.825342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1066</th>\n",
              "      <td>0.790464</td>\n",
              "      <td>0.074110</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>-0.455871</td>\n",
              "      <td>-0.265245</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.275838</td>\n",
              "      <td>-0.070993</td>\n",
              "      <td>0.994863</td>\n",
              "      <td>0.800514</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>-0.09274</td>\n",
              "      <td>-0.508010</td>\n",
              "      <td>0.893677</td>\n",
              "      <td>0.866438</td>\n",
              "      <td>0.825342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>-0.216152</td>\n",
              "      <td>-0.631546</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>-0.134378</td>\n",
              "      <td>-0.177841</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.275838</td>\n",
              "      <td>-0.070993</td>\n",
              "      <td>0.994863</td>\n",
              "      <td>0.109589</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>-0.09274</td>\n",
              "      <td>-0.508010</td>\n",
              "      <td>0.137290</td>\n",
              "      <td>0.866438</td>\n",
              "      <td>0.825342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>0.162505</td>\n",
              "      <td>-0.161109</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>-0.415684</td>\n",
              "      <td>-0.324474</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.275838</td>\n",
              "      <td>-0.070993</td>\n",
              "      <td>0.994863</td>\n",
              "      <td>0.109589</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>-0.09274</td>\n",
              "      <td>-0.133417</td>\n",
              "      <td>-0.619098</td>\n",
              "      <td>0.866438</td>\n",
              "      <td>0.825342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>-0.822944</td>\n",
              "      <td>-0.161109</td>\n",
              "      <td>0.791096</td>\n",
              "      <td>-0.817550</td>\n",
              "      <td>-0.529035</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.275838</td>\n",
              "      <td>-0.070993</td>\n",
              "      <td>0.994863</td>\n",
              "      <td>0.800514</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>-0.09274</td>\n",
              "      <td>-0.508010</td>\n",
              "      <td>1.650065</td>\n",
              "      <td>0.866438</td>\n",
              "      <td>0.825342</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 85 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id  MSSubClass  MSZoning  LotFrontage   LotArea  Street_1  \\\n",
              "254  -1.119284   -0.866764  0.791096    -0.013818 -0.212896         1   \n",
              "1066  0.790464    0.074110  0.791096    -0.455871 -0.265245         1   \n",
              "638  -0.216152   -0.631546  0.791096    -0.134378 -0.177841         1   \n",
              "799   0.162505   -0.161109  0.791096    -0.415684 -0.324474         1   \n",
              "380  -0.822944   -0.161109  0.791096    -0.817550 -0.529035         1   \n",
              "\n",
              "      Street_2  Alley_1  Alley_2  Alley_3  ...  ScreenPorch  PoolArea  \\\n",
              "254          0        1        0        0  ...    -0.275838 -0.070993   \n",
              "1066         0        1        0        0  ...    -0.275838 -0.070993   \n",
              "638          0        1        0        0  ...    -0.275838 -0.070993   \n",
              "799          0        1        0        0  ...    -0.275838 -0.070993   \n",
              "380          0        0        1        0  ...    -0.275838 -0.070993   \n",
              "\n",
              "        PoolQC     Fence  MiscFeature  MiscVal    MoSold    YrSold  SaleType  \\\n",
              "254   0.994863  0.800514     0.960616 -0.09274 -0.133417  1.650065  0.866438   \n",
              "1066  0.994863  0.800514     0.960616 -0.09274 -0.508010  0.893677  0.866438   \n",
              "638   0.994863  0.109589     0.960616 -0.09274 -0.508010  0.137290  0.866438   \n",
              "799   0.994863  0.109589     0.960616 -0.09274 -0.133417 -0.619098  0.866438   \n",
              "380   0.994863  0.800514     0.960616 -0.09274 -0.508010  1.650065  0.866438   \n",
              "\n",
              "      SaleCondition  \n",
              "254        0.825342  \n",
              "1066       0.825342  \n",
              "638        0.825342  \n",
              "799        0.825342  \n",
              "380        0.825342  \n",
              "\n",
              "[5 rows x 85 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xtrain_encoded.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7AuuLRBqyEcL"
      },
      "source": [
        "# Feature Projection\n",
        "This step is for reducing the number of features to keep features that are important."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PCA projection\n",
        "There are many ways to do feature selection, here I'll use PCA method.\n",
        "\n",
        "To be able to apply PCA to reduce the dimension, we need to ensure there are no 'nan' existing in the dataset\n",
        "\n",
        "To ensure non 'nan' presenting in the datasets, I replace value 'nan' with 0 in features. (This can also be resolved by replacing 'nan' with mean or median)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "36-hwTuXzn2i"
      },
      "outputs": [],
      "source": [
        "Xtrain_encoded = Xtrain_encoded.fillna(0)\n",
        "Xval_encoded = Xval_encoded.fillna(0)\n",
        "Xtest_encoded = Xtest_encoded.fillna(0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### PCA features projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "X2S7rmxwxtFM"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(None)\n",
        "Xtrain_pca = pca.fit_transform(Xtrain_encoded)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To determine which features are kept, we need to know the importance of each feature.\n",
        "We can take account of the proportion of variance in the original (encoded) data that is explained by each principal component of the PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpbut3Ug60BS",
        "outputId": "2a19348e-75dc-4e74-a27d-eda8c2bb0813"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['18.30%',\n",
              " '8.53%',\n",
              " '6.82%',\n",
              " '5.20%',\n",
              " '3.95%',\n",
              " '3.15%',\n",
              " '3.05%',\n",
              " '2.97%',\n",
              " '2.95%',\n",
              " '2.85%',\n",
              " '2.78%',\n",
              " '2.68%',\n",
              " '2.63%',\n",
              " '2.60%',\n",
              " '2.55%',\n",
              " '2.37%',\n",
              " '2.27%',\n",
              " '2.14%',\n",
              " '2.09%',\n",
              " '2.00%',\n",
              " '1.90%',\n",
              " '1.72%',\n",
              " '1.61%',\n",
              " '1.48%',\n",
              " '1.33%',\n",
              " '1.09%',\n",
              " '1.02%',\n",
              " '0.87%',\n",
              " '0.75%',\n",
              " '0.69%',\n",
              " '0.62%',\n",
              " '0.53%',\n",
              " '0.42%',\n",
              " '0.35%',\n",
              " '0.30%',\n",
              " '0.27%',\n",
              " '0.23%',\n",
              " '0.22%',\n",
              " '0.19%',\n",
              " '0.18%',\n",
              " '0.17%',\n",
              " '0.17%',\n",
              " '0.17%',\n",
              " '0.15%',\n",
              " '0.14%',\n",
              " '0.13%',\n",
              " '0.12%',\n",
              " '0.12%',\n",
              " '0.11%',\n",
              " '0.10%',\n",
              " '0.10%',\n",
              " '0.07%',\n",
              " '0.07%',\n",
              " '0.07%',\n",
              " '0.06%',\n",
              " '0.06%',\n",
              " '0.05%',\n",
              " '0.05%',\n",
              " '0.05%',\n",
              " '0.05%',\n",
              " '0.04%',\n",
              " '0.04%',\n",
              " '0.04%',\n",
              " '0.03%',\n",
              " '0.03%',\n",
              " '0.03%',\n",
              " '0.02%',\n",
              " '0.02%',\n",
              " '0.02%',\n",
              " '0.02%',\n",
              " '0.02%',\n",
              " '0.01%',\n",
              " '0.01%',\n",
              " '0.01%',\n",
              " '0.01%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%',\n",
              " '0.00%']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "variances = [f\"{comp:.2%}\" for comp in pca.explained_variance_ratio_]\n",
        "variances"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize the cumulative sum of the explained variance ratio as a function of the number of components to help us to determine the remained number of components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "3YbmCzsM7IC6",
        "outputId": "8a48a959-693d-40b6-eee2-68b7254ac40c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/4AAAKyCAYAAABscQVuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACStUlEQVR4nOzdd3hUZeL28XsmvQ4EAiQQSIDQBKQLhI4iLvayirsqKta1AauCuwiKruBPxfraYsW+osKqCIoUjYgIBAst9JBQQptJLzPn/SPJSCRAMpnkJJPv59q5ZuacZ2bu2SvL5s5zznMshmEYAgAAAAAAPslqdgAAAAAAAFB7KP4AAAAAAPgwij8AAAAAAD6M4g8AAAAAgA+j+AMAAAAA4MMo/gAAAAAA+DCKPwAAAAAAPoziDwAAAACAD/M3O4AvcLlcyszMVEREhCwWi9lxAAAAAAA+zjAMZWdnKzY2Vlbrqef0Kf5ekJmZqbi4OLNjAAAAAAAamfT0dLVp0+aUYyj+XhARESGp9L/wyMhIk9MAAAAAAHydw+FQXFycu4+eCsXfC8oP74+MjKT4AwAAAADqTFVON2dxPwAAAAAAfBjFHwAAAAAAH0bxBwAAAADAh1H8AQAAAADwYRR/AAAAAAB8GMUfAAAAAAAfRvEHAAAAAMCHUfwBAAAAAPBhFH8AAAAAAHwYxR8AAAAAAB9G8QcAAAAAwIdR/AEAAAAA8GEUfwAAAAAAfBjFHwAAAAAAH0bxBwAAAADAh1H8AQAAAADwYRR/AAAAAAB8GMUfAAAAAAAfVm+L/zvvvKNbbrlF/fr1U1BQkCwWi958882Tjnc4HJo8ebLatWunoKAgxcfH695771VOTk6l410ul5577jn16NFDISEhio6O1vjx47Vjx45a+kYAAAAAANS9elv8//3vf+uVV17R7t27FRMTc8qxubm5Gj58uObOnasuXbpo0qRJ6ty5s5544gmNGjVKBQUFJ7zmlltu0V133SXDMHTXXXdp7Nix+uSTT9S/f3+lpaXV1tcCAAAAAKBO1dvin5ycrF27dikrK0u33nrrKcc+/vjjSk1N1f3336/Fixdr9uzZWrx4se6//36tWbNGc+fOrTB+2bJlSk5O1rBhw7Ru3TrNmTNH8+bN02effaYjR47ojjvuqM2vBgAAAABAnam3xf/ss89Wu3btTjvOMAwlJycrPDxc06dPr7Bv+vTpCg8PV3JycoXtr776qiRp1qxZCgwMdG8/77zzNGLECC1ZskR79uzxwrcAAAAAAMBc9bb4V1VaWpoyMzOVlJSksLCwCvvCwsKUlJSkHTt2KD093b19+fLl7n1/du6550qSVqxYUbvBAQAAAACoA/5mB6ip8vPxExMTK92fmJioxYsXKy0tTXFxccrNzdW+ffvUvXt3+fn5VTr++PcFAAAA4JtcLkMuw5DLUNn9H48NV+m9s2y74R5T+jrjuNcYKj0S2f0+LsnQH2OOf61Uen/861X6H0ml28tfWzq69L3LH8u93XCP/+N15Y/LH/2xzf28woY/70W5AD+rRndtaXYMr2nwxd9ut0uSbDZbpfsjIyMrjKvu+MoUFhaqsLDQ/dzhcFQzNQAAAFB3XC5DRU6XSlyGSpyu0sdOQyVOQ8Wu0sfFx+0vdhoqcZU/N+Qse+x0GSo+7nmJ0yjb7pLTpQrjSlyGXC7juOd/jHGWleo/xpy4zekqK91l5dxZVrid5c8r7FeF7e79rkpK/XFlHziZpqEBWv/gGLNjeE2DL/5meOyxx/TQQw+ZHQMAAAD1gNNlqKjEVXorK9Xlz4udLhWW3R+/rei47cVlryt2Gu73KD5uXFFJaSkvvxU5Dfd+9/OyxyXOsoJf9n7l2ym5NWO1SFaLRVaLRRaLZLFIfhaLLGXPrcfdWy0q3a5Tj7NYJIuOf1x6X678PVT2PuX7jh9n0XEDyp6fsK/svY5X8RkqExHsW1W5wX+b8pn7k83Ql8/Gl4+r7vjKTJs2TZMnT67wmri4uGomBwAAgDc4XYYKS5wqKHa57wuKnSos+eO+sNipgj/dFx5/X1L62sJiV8Xn5Y+LnSoqe3x8sS9yuuRsgK3aYpECrFb5+1nkb7UowK/8sVUBfhb5+1nd2/2spWPK9/tZLQrws5Rt/2O/X9kYP6tFfhaL/Mrev3y/1VK2z3r8mNKbtey5f/ljq/4Yb/lj//FjrVZV2Ga1HLe9ktdZjivvVusfj/0sFlmsf5R295jjC7qFqoyGrcEX/9Odk//nNQDCwsIUExOjnTt3yul0nnCe/+nWDJCkoKAgBQUF1Tg7AACArzIMQ4UlLuUVOZVf7FR+kVMFxc4TnueXbSs4bltBiVP5RS4VlDhLi3qxS/nFZfuK/yj4hcWlY4qd9at4B/pZFehfegvws5Q+9rMq0N9PgeXP/a0K8LP+Mdav7HnZ9gB/i4L8yh+Xjy0t4uXbyp/7+5V+Tvn7+ftZyu7/2B5w3OPSEt/g1/gGUA0+UfxjY2OVkpKi3NzcCiv75+bmKiUlRQkJCRVm5IcPH64PPvhAKSkpGjZsWIX3W7x4sSSdsB0AAMAXGYah/GKncgpLlFfoVG5RifKKnMotLL0vvZU9LixR7p+3ld3nu7c7lV9UovxipymHlwf4WRTs76egAKuC/P0UXHYfFGB1b//zfZB/2Rh/q/t1xz8O9Ct9fHyhD/K3KtDPz/3cXfL9rMwOA6h3Gnzxt1gsmjhxoh5++GHNmjVLs2fPdu+bNWuWcnJy9MADD1R4zc0336wPPvhA06dP19dff63AwEBJ0qJFi7R8+XKNGTNG7dq1q9PvAQAAUFUul6HsghLZ84vlKChWdkGJcgtLlFtU4i7wOYXHbyst7TmFf5R69+Oikj+t8u19gf5WhQT4ld4CK94HB/gp1P3YquBAPwX7l24PDrC6xwQHWBVU9h5B/taybX8U+/J7PyulGwD+zGIYtf1PvWeSk5P1/fffS5J+/fVXrVu3TklJSerYsaMkaciQIZo4caKk0pn9pKQkbdiwQWPGjFGfPn20bt06LVmyRP3799eKFSsUEhJS4f1vuukmJScn64wzztC4ceO0b98+ffjhhwoPD9eqVavUqVOnKmd1OByy2Wyy2+3uqwIAAACcistlKLuwRI78Ytnzi3Usr/Tenl+sY/lFpaU+/49t7ltesbILa6eshwX6KTTIX+FB/goJ8FNYkJ9CA/0VGlh6HxZUWtjDyraVPw4J9Csb46eQAP8/HpcVeg4rBwDvq04PrbfFf8KECXrrrbdOuv+6667Tm2++6X5ut9s1c+ZMzZ8/X/v371dMTIyuuOIKzZgxQxERESe83uVy6fnnn9crr7yibdu2KTw8XGeffbYeffRRdejQoVpZKf4AADRuJU6XjuYV61hekY7kFuloXpGO5hWXPs4tfXy0bN+xvCIdKyv1NT0UPiTAT7aQAIUH+yssyF9hgX4KKyvuYUGlpTws6MR9oWWPw44bFxLgJyuz5QDQYPhE8W9IKP4AAPgOwzCUU1iiwzlFOlxW3I/kld3n/lHsj+T+Ue7t+cUef15wgFW2kAA1CQmULSRAkSEBahIaIFvIibfIPz0P9GcmHQAaq+r00AZ/jj8AAMDpFBQ7lZVdqEM5hTqUU6RDOYU6nFOow8eV+cM5fzwucro8+pwmoQGKCg0svQ8LVNPQQDUtu48KC1CT0LJtoX8U+eAAv9O/MQAANUDxBwAADVJhiVOHcoqUlV1Y8ZZToEPZRWUlv7To5xSWVPv9QwL8FBUWqGbhgYoKC1RUWYmPchf58luAmoaWztZzLjsAoD6i+AMAgHolv8ipA44C7XcU6ICjQAcdhTrgKNCB7EJlZReUzdxX//D6QH+rosOD1Dw8UM3Dg8oKfZCalRf48ED342ZhQQoJZCYeAOAbKP4AAKBOGIYhR36JMu352mfPV+axAu2z52uf/Y9yv99RoOyCqs/OB/pZFR0RpOYRQYoODyx9HB7kvm9eXvQjghQR5M/11QEAjRLFHwAAeEVuYUmFQn98sc88VnqfV+Ss0nuFBPiplS1YLSKC1DIy2P04uuzWIiJI0eHBigyhzAMAcDoUfwAAcFrFTpf2lxX4zLJSX17my++reuh909AAxdhCFNskWDG2ELWyBatVZHBZwQ9Si8hgZucBAPAiij8AAFBOYYkyjuYr41ieMo4VKONovjKP5SvjWOn9AUdBla45HxHkr5iyQl9e7GNswYptUnofYwvh3HkAAOoYxR8AgEYgu6BYe4/ml93ytPdovjKO5mvvsdLHx/JOP1sf6Gd1l/nYJscV+ybBal1W7COCA+rg2wAAgOqg+AMA4AOKSlzKOJavPUfytOdInvaW3e85Ulrsq3IYvi0kQK2bhKh105DS+yalBb9109KS3zwsSFYrh98DANDQUPwBAGggcgtLtPNQrnYdztXOrFx3sU8/kqd9jgIZpzkUPyosUK2bhKhN0/JbqPu+ddMQhQfxawEAAL6I/4cHAKAeKSxxKv1InnZk5bpL/o6s0vsDjsJTvjYkwE9to0IVFxWquKgQtY0KVduoUHfBD6PYAwDQKPEbAAAAJjiWV6TtWTnafjBX27JytP1gjrZn5WjPkbxTLqIXFRaohOZhim8WpvhmoWrbrKzoNw1V8/BAVsIHAAAnoPgDAFCLjuUVaeM+hzbty9a2snK//WCODucWnfQ1YYF+SogOU0LzcCU0Cz3ucZhsoSyeBwAAqofiDwCAFxiGob1H8/V7pkMb9zm0MdOhTfscyjiWf9LXxNiC1bFFuDpEh6tDdFjpfYtwtYgIYuYeAAB4DcUfAIBqcroM7cjK0S977fo1w142o+9QdkFJpePjokLUtVWkOreKKCv54UqIDmMxPQAAUCf4jQMAgFNwugztPPRHyf8tw67fMx3KK3KeMDbQz6rEluHqFhOpbrGR6hYTqS4xkbKFcHg+AAAwD8UfAIDjZGUXas2uI1q7+6h+3WvXb5n2Skt+aKCfusfa1L21TWfElhb9DtHhCvS3mpAaAADg5Cj+AIBGyzAM7T6cp592HdHPu45oza6j2nko94RxIQF+OiM2Uj3a2NSjtU0929iU0DxcflbOwwcAAPUfxR8A0Gi4XIY27Xdozc7Skv/TriPKyi6sMMZikTq3jFD/+Cj1imuiHm1s6hBNyQcAAA0XxR8A4NOO5Bbpu7QsLd+SpZVbs064jF6gn1U929jULz5KAxKaqm/bKC6ZBwAAfArFHwDgU5wuQ6npx7Ria5ZWbDmoXzLsMow/9ocF+qlffJT6xzdV//gonRnXRMEBfuYFBgAAqGUUfwBAg2fPK9bXmw5o+ZaD+i7tkOz5xRX2d42J1PBO0RrROVp92jZlAT4AANCoUPwBAA1SYYlTyzYf1KfrM7Rsc5aKnC73vshgfw3tFK3hZbeWkcEmJgUAADAXxR8A0GC4XIbW7jmqT9Zl6ItfMuUoKHHv69IqQud0a6kRnaN1Zpsm8vdjVh8AAECi+AMAGoDtWTn6bH2GPl2fob1H893bW0UG66Lesbqkd2t1aRVpYkIAAID6i+IPAKiX8opK9Nn6TH2wZo9+2Wt3bw8P8tfY7q10ae/WOqt9My6zBwAAcBoUfwBAvbLzUK7mrdqt/65NV3bZofx+VouGd4rWxb1b65yuLRUSyCr8AAAAVUXxBwCYzukytGLrQb31w26t2Jrl3t6uWaiuGdhOF/durebhQSYmBAAAaLgo/gAA0xzLK9JHP6frnR/3aM+RPEmSxSKN7NxC1w5qp2GJ0bJyKD8AAECNUPwBAHVu836H3vh+lz5LzVBhSell+GwhAbqyf5z+flY7tW0WanJCAAAA30HxBwDUmTW7jujF5dv17eaD7m3dYiJ13eB2uvDM1py7DwAAUAso/gCAWuVyGfp280G9tGK7ft59VJJktUjndY/R9Unx6tuuqSwWDucHAACoLRR/AECtKHa6tDA1Uy+v3K6tB3IkSYF+Vl3Wt41uHtZeCc3DTE4IAADQOFD8AQBelVdUog/XpCv5u53KOJYvSYoI8tffBrbTDUnxahEZbHJCAACAxoXiDwDwipzCEr2ZslOvfb9TR/OKJUnNw4N045AE/W1gW0UGB5icEAAAoHGi+AMAaiS/yKm3V+3SSyu2uwt/26hQ3TK8vS7r00bBASzYBwAAYCaKPwDAIwXFTr3/0x69sGy7DuUUSpISmofpnrMTNa5HjPz9rCYnBAAAgETxBwBUU1GJS/9dm67nv92mffYCSVJcVIjuGpWoS3q3pvADAADUMxR/AECVlDhd+mR9hp5dmqa9R0sX7YuxBevOUYm6vG8bBfpT+AEAAOojij8A4JQMw9CXv+7XE0u2aOehXElSdESQ/jGig64a0JZz+AEAAOo5ij8A4KQ273do5sLf9eOOI5KkqLBA3Tq8va4ZGK+QQAo/AABAQ0DxBwCcwJ5XrLnfbNW8H3fL6TIU5G/VbSM6aOLQ9goP4v86AAAAGhJ+ewMAuDldhj76OV3/t3iLjuQWSZLO695K/xrXVW2ahpqcDgAAAJ6g+AMAJEnr9hzVjAW/69cMuyQpsUW4Zl54hpI6Njc5GQAAAGqC4g8AjdzB7ALNWbRF89ftlSRFBPnrnnM66dpB7RTApfkAAAAaPIo/ADRSLpeht1bt0pNLtiqnsESSdEXfNrpvbBdFRwSZnA4AAADeQvEHgEYo41i+/vnRBq3acViSdGYbm2ZeeIZ6t21qcjIAAAB4G8UfABoRwzD06foMzVjwu7ILSxQS4KcHxnXV3wa0ldVqMTseAAAAagHFHwAaiSO5RfrXp79q0W/7JUl92jbRU3/tpfjmYSYnAwAAQG2i+ANAI7Bsy0Hd9/EvysoulL/VoknndNItw9rLn8X7AAAAfB7FHwB8WG5hiR79cpPeW71HUukl+uZe2UvdW9tMTgYAAIC6QvEHAB+1bs9RTf4wVbsO50mSbkhK0H1jOys4wM/kZAAAAKhLFH8A8DElTpeeXZqm55dtk8uQYm3BeuKKMzW4Y3OzowEAAMAEFH8A8CGZx/J19wfrtWbXUUnSJb1ba+aFZ8gWEmByMgAAAJjFZ1Z1crlcev7559WnTx+FhoYqMjJSw4YN08KFCysd73A4NHnyZLVr105BQUGKj4/Xvffeq5ycnDpODgDe8c3GA/rLs99pza6jCg/y17Pje2vulb0o/QAAAI2cxTAMw+wQNWUYhq644grNnz9fHTp00HnnnafCwkItWLBABw8e1HPPPac77rjDPT43N1dDhgxRamqqxowZo969e2v9+vVasmSJ+vfvr5UrVyo4OLjKn+9wOGSz2WS32xUZGVkbXxEATqqoxKU5X23Wa9/vlCT1aG3T81f3VrtmXKYPAADAV1Wnh/pE8f/44491xRVXKCkpSV9//bVCQkIkSYcOHVK/fv20f/9+bd68WfHx8ZKkGTNm6OGHH9b999+v2bNnu99n6tSpmjNnjv7zn/9o2rRpVf58ij8As+w5nKc731+nDXvtkkoX8Lv/vM4K8mcBPwAAAF9WnR7qE4f6L1iwQJL0wAMPuEu/JDVv3lyTJk1SYWGh3njjDUmlRwckJycrPDxc06dPr/A+06dPV3h4uJKTk+suPAB46PNfMjXu2e+0Ya9dtpAAvXptPz14QTdKPwAAACrwieK/f/9+SVJCQsIJ+8q3ffvtt5KktLQ0ZWZmKikpSWFhFQ+DDQsLU1JSknbs2KH09PRaTg0Anikodupfn/6qO95br+zCEvVt11Rf3j1U53RraXY0AAAA1EM+UfybNy+9RNXOnTtP2Fe+bevWrZJKi78kJSYmVvpe5dvLx1WmsLBQDoejwg0A6sK2gzm6+IUUvbt6jywW6fYRHfTBzQPVuknI6V8MAACARskniv95550nSZo9e7YKCgrc2w8fPqynn35aknTs2DFJkt1eeh6szWar9L3Kz40oH1eZxx57TDabzX2Li4ur6VcAgNP6YdshXfxCijbvz1bz8EC9df0A3Te2iwL8fOKfcgAAANQSf7MDeMPVV1+tN998U8uWLVOPHj00duxYFRcX67PPPlPLlqWHvlqt3vvFeNq0aZo8ebL7ucPhoPwDqFWf/5KpyR9uUJHTpQEJUXp+fG+1iKz61UcAAADQePnENJG/v78WLVqkmTNnymq16pVXXtEnn3yiiy66SB9//LEkqUWLFpL+mOk/2Yx++WH7JzsiQJKCgoIUGRlZ4QYAteWtH3bpzvfXq8jp0l96tNK8GwdQ+gEAAFBlPjHjL5WW8RkzZmjGjBkVti9fvlyS1K9fP0mnP4f/dGsAAEBdMQxDT329Vc99u02SdO2gdppxwRnys1pMTgYAAICGxGeK/8m8++67kqSrrrpKUmmhj42NVUpKinJzcyus7J+bm6uUlBQlJCRw6D4AU5U4Xfr3Z7/pgzWlVxiZck4n3TGqoywWSj8AAACqxycO9ZdU6cr6H3/8sV5//XX1799fl156qSTJYrFo4sSJysnJ0axZsyqMnzVrlnJycnTTTTfVSWYAqExBsVO3vbtOH6xJl9UiPXZpD905OpHSDwAAAI9YDMMwzA7hDV27dlVcXJy6du2q4OBg/fTTT1q+fLnat2+vb7/9Vu3atXOPzc3NVVJSkjZs2KAxY8aoT58+WrdunZYsWaL+/ftrxYoVCgmp+qWxHA6HbDab7HY75/sDqBF7XrEmvr1Ga3YdVZC/Vc+O761zz2hldiwAAADUM9XpoT5T/GfOnKlPPvlEu3btUnFxsRISEnTZZZfp3nvvrfS/BLvdrpkzZ2r+/Pnav3+/YmJidMUVV2jGjBmKiIio1mdT/AF4w357ga57/SdtOZCtiGB/vXZdfw1IiDI7FgAAAOqhRln8zUTxB1BT2w7m6LrXf1LGsXy1jAzSWzcMUJdW/HsCAACAylWnh/r84n4AUN9tzHTob8k/6mhesdpHh+ntGwaoTdNQs2MBAADAR1D8AcBEm/b9UfrPbGPTG9cPUFRYoNmxAAAA4EMo/gBgks37Hfpb8urS0h/XRPNuHKDI4ACzYwEAAMDH+Mzl/ACgIdmyP1tXv7paR3KL1LONTW/fQOkHAABA7aD4A0Ad23ogW1e/+qOO5BapR2ub5t1wlmwhlH4AAADUDoo/ANShtLLSfzi3SN1bR+qdG8+SLZTSDwAAgNpD8QeAOrLtYLbGv7pah3KKdEYspR8AAAB1g+IPAHVg28EcXfXKah3KKVS3mEi9O/EsNQll9X4AAADUPoo/ANSybQdzNP7VH3Uop1BdKf0AAACoYxR/AKhF27NKS39WdqG6tIrQuxPPUtMwSj8AAADqDsUfAGpJ+pE8XX1c6X/vpoGKovQDAACgjlH8AaAWHMop1DWvrdYBR6E6tQzXuxPPovQDAADAFBR/APCy7IJiTXjjJ+06nKc2TUM078az1Cw8yOxYAAAAaKQo/gDgRYUlTt0yb61+y3CoWVig3r5hgFpGBpsdCwAAAI0YxR8AvMTpMjTpw1T9sP2wwgL99Ob1A9Q+OtzsWAAAAGjkKP4A4AWGYWjGwt/05a/7Fehn1SvX9lOPNjazYwEAAAAUfwDwhmeWpumdH/fIYpHmXtlLSR2bmx0JAAAAkETxB4Aam/fjbj39TZok6eELz9C4njEmJwIAAAD+QPEHgBr44pd9enDBb5Kku0cn6ppB8eYGAgAAAP6E4g8AHvph2yFN+jBVhiH97ay2uufsRLMjAQAAACeg+AOAB37LsOumt39WkdOlv/RopYcv6i6LxWJ2LAAAAOAEFH8AqKY9h/M04Y2flFvk1OAOzTT3yl7ys1L6AQAAUD9R/AGgGuz5xbr+zZ90KKdIZ8RG6uVr+irI38/sWAAAAMBJUfwBoIqKnS7d/u5abc/KVYwtWK9P6K+I4ACzYwEAAACnRPEHgCowDEPTP/tNKdsOKyzQT69d118tI4PNjgUAAACcFsUfAKrglZU79MGadFkt0nNX91a32EizIwEAAABVQvEHgNP46rd9mv3VZknS9PO7aVSXliYnAgAAAKqO4g8Ap/DL3mO658NUGYZ07aB2mjA43uxIAAAAQLVQ/AHgJDKP5evGt35WQbFLwztF68Hzu8li4bJ9AAAAaFgo/gBQiZzCEt3w5hplZReqc8sIPX91b/n78U8mAAAAGh5+iwWAPylxunTne+u0eX+2mocH6bUJ/bhsHwAAABosij8A/MkjX2zSsi1ZCvK3Kvm6fmrTNNTsSAAAAIDHKP4AcJy3ftilN3/YJUmae2Uv9YprYmoeAAAAoKYo/gBQ5vu0Q3rof79Lku4b21l/6RFjciIAAACg5ij+AKDSFfzv+mC9XIZ0WZ82um14B7MjAQAAAF5B8QfQ6BWVuPSP99bpSG6RusVE6tFLunPZPgAAAPgMij+ARu8/X27S+j3HFBnsr5f+3lfBAX5mRwIAAAC8huIPoFFbuCHTvZjfU3/tpbbNWMEfAAAAvoXiD6DR2nYwW1Pn/yJJun1EB53draXJiQAAAADvo/gDaJRyC0t06zvrlFfk1KD2zTT5nE5mRwIAAABqBcUfQKNjGIamfvKrth3MUYuIID07vrf8/fjnEAAAAL6J33QBNDpvr9qt/23IlL/Vov/3tz6KjggyOxIAAABQayj+ABqVdXuO6pEvNkqSpp7XRf3io0xOBAAAANQuij+ARuNwTqH+8e46FTsN/aVHK904JMHsSAAAAECto/gDaBScLkP3fJiqffYCtW8epjmX9ZTFYjE7FgAAAFDrKP4AGoVnvtmq79IOKSTATy/+va8iggPMjgQAAADUCYo/AJ+3YmuWnv12myTpsUt7qHOrCJMTAQAAAHWH4g/Apx10FGjyh6mSpL+d1VYX925tbiAAAACgjlH8Afgsl8vQ5I826HBukbq0itD087uZHQkAAACocxR/AD7rpZXb9f220vP6n7+6t4ID/MyOBAAAANQ5ij8An7R291E9uWSrJOmhC89Qxxac1w8AAIDGieIPwOfY84t11/vr5XQZuvDMWF3Rr43ZkQAAAADTUPwB+BTDMDR1/i/KOJavtlGhevSS7rJYLGbHAgAAAExD8QfgU977aY8W/bZf/laLnhvfWxHBAWZHAgAAAEzlM8XfMAx98sknGjlypGJiYhQaGqrOnTvrlltu0Y4dO04Y73A4NHnyZLVr105BQUGKj4/Xvffeq5ycHBPSA/CGLfuz9fD/NkqS7h/bRWfGNTE3EAAAAFAPWAzDMMwO4Q1TpkzRU089pZiYGF100UWKjIzUhg0btGTJEoWHh+uHH35Q9+7dJUm5ubkaMmSIUlNTNWbMGPXu3Vvr16/XkiVL1L9/f61cuVLBwcFV/myHwyGbzSa73a7IyMja+ooATiG/yKkLn/9eaQdzNLxTtN6Y0F9WK4f4AwAAwDdVp4f611GmWrV//349/fTTateunTZs2CCbzebeN3fuXE2ePFlPPfWUXn/9dUnS448/rtTUVN1///2aPXu2e+zUqVM1Z84czZ07V9OmTavz7wHAcw9/vlFpB3MUHRGkJ/96JqUfAAAAKOMTh/rv2rVLLpdLSUlJFUq/JJ1//vmSpKysLEmlpwQkJycrPDxc06dPrzB2+vTpCg8PV3Jyct0EB+AVn/+Sqfd/2iOLRXr6yl5qHh5kdiQAAACg3vCJ4p+YmKjAwEClpKTI4XBU2Pf5559LkkaPHi1JSktLU2ZmppKSkhQWFlZhbFhYmJKSkrRjxw6lp6fXTXgANZJ+JE/T5v8qSbp9RAcldWxuciIAAACgfvGJQ/2bNWum2bNna8qUKerSpUuFc/y//fZb3X777brjjjsklRZ/qfSPBZVJTEzU4sWLlZaWpri4uErHFBYWqrCw0P38z39sAFA3ip0u3fn+emUXlqhvu6a65+xOZkcCAAAA6h2fKP6SNGnSJLVu3VoTJ07USy+95N4+ZMgQXX311fL3L/2qdrtdkk44JaBc+aII5eMq89hjj+mhhx7yVnQAHnr6m61KTT+myGB/PXNVLwX4+cRBTAAAAIBX+cxvyQ8//LD+/ve/64EHHlB6erqys7P13XffqaCgQCNGjNDChQu99lnTpk2T3W533zgtAKh7P+08ov+3fLskafZlPdWmaajJiQAAAID6ySeK/zfffKMZM2bojjvu0NSpU9WmTRuFh4dryJAh+t///qeAgABNmTJF0h8z/Seb0S8/bP9kRwRIUlBQkCIjIyvcANQdR0GxJn2YKsOQLu/bRn/pEWN2JAAAAKDe8oniv2jRIknSyJEjT9jXqlUrdenSRdu2bVNOTo773P7yc/3/7HRrAAAw38yFvyvjWL7iokI044JuZscBAAAA6jWfKP5FRUWS/rhk359lZWXJarUqICBAiYmJio2NVUpKinJzcyuMy83NVUpKihISEk66sB8Ac33+S6Y+WZchq0Wa+9deiggOMDsSAAAAUK/5RPFPSkqSJD311FMnHML/0ksvae/evRo0aJCCgoJksVg0ceJE5eTkaNasWRXGzpo1Szk5ObrpppvqLDuAqttnz9e/Pv1NkvSPkR3VLz7K5EQAAABA/WcxDMMwO0RNOZ1OjRo1SitXrlSLFi104YUXqkmTJlq3bp2+/fZbhYSEaPny5RowYICk0pn9pKQkbdiwQWPGjFGfPn20bt06LVmyRP3799eKFSsUEhJS5c93OByy2Wyy2+2c7w/UEpfL0DWvr1bKtsPq2cam+bcNZhV/AAAANFrV6aE+UfwlqbCwUHPnztVHH32kLVu2qKioSC1bttTIkSP1wAMPqGvXrhXG2+12zZw5U/Pnz9f+/fsVExOjK664QjNmzFBERES1PpviD9S+5O926JEvNikkwE9f3DVE7aPDzY4EAAAAmKZRFn8zUfyB2rV5v0MXPpeiIqdLj17SXX87q53ZkQAAAABTVaeHcpwsgHqtoNipez5IVZHTpdFdWujqAW3NjgQAAAA0KBR/APXaE4u3aPP+bDUPD9Scy3vKYrGYHQkAAABoUCj+AOqtlG2HlPz9TknSnMt6qnl4kMmJAAAAgIaH4g+gXjqWV6QpH22QJP3trLYa3bWlyYkAAACAhoniD6DeMQxD//r0N+13FKh98zD9a1zX078IAAAAQKUo/gDqnc9SM/TFr/vkb7Xo6at6KTTQ3+xIAAAAQINF8QdQr2Qey9eDC36XJN09OlE92zQxNxAAAADQwFH8AdQbLpehez/eoOyCEvWKa6LbRnQwOxIAAADQ4Hl0/OyxY8e0ePFiLV26VOvWrdOBAwd09OhRNW3aVC1btlTfvn01atQonXvuuWrSpImXIwPwVfN+3K2UbYcVHGDVU389U/5+/G0SAAAAqCmLYRhGVQf/+uuveuaZZ/T++++roKBAp3qpxWJRcHCwrr76at15553q2bOnVwLXRw6HQzabTXa7XZGRkWbHARqk7Vk5Gvfsdyoodunhi87QtYPizY4EAAAA1FvV6aFVKv4HDx7UtGnT9NZbb8nlcql58+YaMWKEBg8erDPOOEPNmjVTZGSk7Ha7Dh8+rN9++00//PCDVq5cqUOHDslqtWrChAn6z3/+oxYtWnjti9YXFH+gZkqcLl320iptSD+moYnN9db1A2S1WsyOBQAAANRbXi/+NptN2dnZOv/883XjjTdq3Lhx8vc//VkCJSUl+t///qfXX39dX3zxhWw2m44ePVr1b9JAUPyBmnluaZqe/HqrIoL9tWTSMMXYQsyOBAAAANRr1emhVTqBdsCAAVqzZo0WLlyoiy66qEqlX5L8/f11ySWX6H//+59Wr16tfv36Vel1ABqP3zLsemZpmiRp1kXdKf0AAACAl1XrHH9Ujhl/wDMFxU5d8Nz3SjuYo/O6t9L/+1sfWSwc4g8AAACcjtdn/AGgNjy5ZIvSDuaoeXiQHrm4O6UfAAAAqAUUfwCmWL3jsJK/3ylJmn1pDzULDzI5EQAAAOCbvFb8v/jiCw0ZMkTh4eGKiIjQiBEj9M0333jr7QH4kJzCEk357wYZhnRlvzid3a2l2ZEAAAAAn+WV4v/RRx/pggsuUGpqqrp27aq4uDitXLlSY8eO1VdffeWNjwDgQx75fKP2Hs1Xm6Yh+vf5Xc2OAwAAAPg0rxT/6dOna8iQIdqzZ4/WrFmjjRs3avny5QoKCtLMmTO98REAfMTSTQf0wZp0WSzSE1ecqYjgALMjAQAAAD6tSsX/hx9+OOm+wsJCpaWlacqUKYqKinJvHzZsmMaMGaMNGzbUPCUAn3Akt0j3z/9VkjRxSIIGtm9mciIAAADA91Wp+A8dOlT/+Mc/lJ2dfcK+gIAABQQEKDMz84R9mZmZCgsLq3lKAD5hxsLfdSinUIktwjVlTGez4wAAAACNQpWK/z333KNXXnlFXbt21WeffVbxDaxWnXPOOfr3v/+t119/XZs2bdLPP/+sW2+9VT///LPGjh1bG7kBNDBfbzyg/23IlNUiPfnXMxUc4Gd2JAAAAKBRsBiGYVRl4Lp163TTTTcpNTVVF198sZ577jnFxsZKknbt2qURI0YoPT3dPd4wDHXs2FErVqxQTExM7aSvJxwOh2w2m+x2uyIjI82OA9Q7joJinfPUCh1wFOqW4e017TwW9AMAAABqojo9tMrFX5JcLpeefvppzZgxQ35+fpo9e7ZuvfVWSVJOTo7effddbdiwQRaLRX369NH48eMVGhpas2/TAFD8gVN74NNf9d7qPYpvFqqv7hnGbD8AAABQQ7VW/Mvt3r1bt99+uxYtWqTBgwfr1VdfVdeujXcGj+IPnNyq7Yc1/tUfJUkf3DyQBf0AAAAAL6hOD/Xocn7t2rXTF198offee0/bt29X7969NWPGDBUVFXkUGIBvyi9yatonv0iSrj6rLaUfAAAAMIFHxb/cVVddpc2bN+uaa67RI488ol69eum7777zVjYADdzT32zVrsN5ahUZrKnndTE7DgAAANAoVbn4OxwOPfXUU7r88ss1duxY3XjjjVq4cKFsNpteffVVLVu2TIZhaMSIEbrllltkt9trMzeAeu6Xvcf06nc7JEmPXNxdkcEBJicCAAAAGqcqneN//Kr9xw+3WCwaP3683nnnHUlSUVGR/vOf/2j27NmKiorSs88+q8svv7z20tcTnOMPVFTsdOmC577X5v3ZuvDMWD07vrfZkQAAAACf4vVz/CdPnqw9e/boX//6l/bu3av8/HytXbtWw4YN0/vvv6/PPvtMkhQYGKiZM2cqNTVVHTt21JVXXqkLL7ywxl8IQMPy8ort2rw/W01DAzTjgm5mxwEAAAAatSoV/6VLl2rUqFF6+OGHFRsbq6CgIPXu3Vtvv/22DMPQsmXLKozv0qWLVq5cqRdffFHff/99rQQHUD9tO5itZ5dukyTNuOAMNQsPMjkRAAAA0LhVqfgbhiGLxXLC9vJtJztb4Oabb9bmzZtrEA9AQ+JyGbp//q8qcro0snO0LuoVa3YkAAAAoNGrUvEfMWKEvv32Wz3yyCPav3+/ioqKtGHDBl133XWyWCwaMWLESV/bokULb2UFUM/N+3G31u4+qrBAPz16SY9K/2AIAAAAoG5VaXG/7du3a+TIkdq7d2+FX+QNw9BVV12l9957r1ZD1ncs7gdIe4/maczclcorcmrWxd11zcB2ZkcCAAAAfFZ1eqh/Vd6wQ4cO2rp1q15++WWtXbtWhw8fVnx8vC666CKNGTPGK6EBNFyGYeiBT39TXpFTA+Kj9LcBbc2OBAAAAKBMlYq/JAUHB+vuu++uzSwAGqhP1mVo5dYsBfpbNfuyHrJaOcQfAAAAqC+qdI4/AJzM0dwiPfrlJknS3aMT1T463OREAAAAAI5XpeKfn5/vlQ/z1vsAqD8eW7RJR3KL1KVVhG4e1t7sOAAAAAD+pErFv0OHDnrppZfkdDo9+pCSkhK98MIL6tChg0evB1A//bTziD76ea8k6dFLuivAj4OIAAAAgPqmSr+lx8bG6vbbb1d8fLz+/e9/Ky0trUpvvmXLFk2bNk3x8fG688471bp16xqFBVB/FJW49MCnv0qSxg+IU992USYnAgAAAFCZKl3OzzAMJScn69///reysrJksVjUpk0bDRo0SF27dlWzZs0UGRkph8Ohw4cPa+PGjVq1apUyMjJkGIaio6P16KOP6sYbb/TJ63pzOT80Ri8s26b/W7xFzcICtXTKcDUJDTQ7EgAAANBoVKeHVqn4lysoKNC8efP0/PPP69dfS2f6Kivy5W/Zs2dP3XHHHfrb3/6mkJCQ6nyHBoXij8Zm9+FcjZm7UoUlLs298kxd0ruN2ZEAAACARqXWiv/xdu3apW+//Vbr16/XgQMHZLfb1aRJE7Vo0UJ9+vTRyJEjFR8f78lbNzgUfzQmhmHoujfWaOXWLCV1bKZ3bjzLJ4/kAQAAAOqz6vRQf08/JD4+XjfccIOnLwfQQH3x6z6t3JqlQD+rZl3UndIPAAAA1HMswQ2gyhwFxXrofxslSbeP7KD20eEmJwIAAABwOhR/AFX2xOItysouVPvmYbptBJfnBAAAABoCij+AKklNP6Z5P+6WJD1ycXcF+fuZnAgAAABAVVD8AZxWidOlBz75VYYhXdK7tQZ3bG52JAAAAABVRPEHcFpv/rBLG/c5ZAsJ0L/GdTU7DgAAAIBqoPgDOKXMY/l66uutkqSp53VR8/AgkxMBAAAAqA6KP4BTmrnwd+UVOdWvXVNd2S/O7DgAAAAAqoniD+Ckvt54QEs2HpC/1aJHL+khq9VidiQAAAAA1eSV4l9UVKR9+/bpyJEj3ng7APVAQbFTD/3vd0nSjUMT1LlVhMmJAAAAAHiiRsX/nXfe0YABAxQWFqY2bdron//8p3vfp59+qquvvlo7d+6sccjTefPNN2WxWE55Gz16dIXXOBwOTZ48We3atVNQUJDi4+N17733Kicnp9bzAg3Ba9/v1N6j+WoVGay7RyeaHQcAAACAh/w9feHEiRP1xhtvyDAMhYeHn1CYO3XqpA8++EB9+vSp8AeB2tCrVy/NmDGj0n0ff/yxfv/9d5177rnubbm5uRo+fLhSU1M1ZswYjR8/XuvXr9cTTzyhFStWaOXKlQoODq7VzEB9dsBRoBeWbZMk3X9eZ4UGevxPBQAAAACTefTb/LvvvqvXX39dPXr00Ouvv64+ffrIz8+vwpgzzjhDbdq00aJFi+qk+Pfq1euE7UVFRXr++efl7++v6667zr398ccfV2pqqu6//37Nnj3bvX3q1KmaM2eO5s6dq2nTptVqZqA+e/yrLcorcqpXXBNddGZrs+MAAAAAqAGPDvV/5ZVXFB4ers8//1x9+/aVxVL5gl89evSok0P9T+azzz7T4cOHdf7556tly5aSJMMwlJycrPDwcE2fPr3C+OnTpys8PFzJyclmxAXqhQ3pxzR/3V5J0owLurGgHwAAANDAeVT8N2zYoLPOOktxcae+tFdUVJQOHDjgUTBvKC/wEydOdG9LS0tTZmamkpKSFBYWVmF8WFiYkpKStGPHDqWnp9dpVqA+MAzDvaDfpb1bq3fbpiYnAgAAAFBTHhX/wsJC2Wy2047Lyso64RSAurJ7924tXbpUbdq00dixY93b09LSJEmJiZUvVla+vXxcZQoLC+VwOCrcAF+wcEOm1u05ppAAP903tovZcQAAAAB4gUfFv3Xr1tq0adMpxxiGoY0bNyohIcGjYDX1xhtvyOVyacKECRX++GC32yXppH+4iIyMrDCuMo899phsNpv7drojH4CGIK+oRLMXbZYk/WNkB7WyscAlAAAA4As8Kv6jR4/W5s2btWDBgpOOmTdvnvbu3atzzjnH43CecrlceuONN2SxWHTDDTd4/f2nTZsmu93uvnFaAHzBSyt2aJ+9QK2bhGji0PZmxwEAAADgJR4V/3/+858KCgrS1VdfraefflqZmZnufUeOHNFLL72k22+/XWFhYbrrrru8FraqvvnmG+3Zs0ejRo064YiD8pn+k83olx+2f6pTGYKCghQZGVnhBjRkGcfy9fKK7ZKkB/7SVcEB5pyiAwAAAMD7PCr+iYmJeuutt+RyuTRlyhTFxcXJYrHorbfeUnR0tP7xj3+opKREb775ptq2bevtzKdV2aJ+5U53Dv/p1gAAfNFjX25SYYlLAxKi9JcercyOAwAAAMCLPCr+knTFFVdozZo1uuKKKxQRESHDMGQYhoKDg3XBBRdo1apVuuyyy7yZtUoOHz6sBQsWKCoqSpdccskJ+xMTExUbG6uUlBTl5uZW2Jebm6uUlBQlJCRw3j4ajTW7jujzX/bJYpEePL/bSS/PCQAAAKBh8rj4S1L37t31wQcf6OjRozp48KD279+v7OxsffbZZ+rdu7e3MlbLvHnzVFRUpL///e8KCgo6Yb/FYtHEiROVk5OjWbNmVdg3a9Ys5eTk6KabbqqruICpXK4/Lt93Zb84dW99+qt1AAAAAGhYLIZhGGaH8KYePXrot99+0y+//KIePXpUOiY3N1dJSUnasGGDxowZoz59+mjdunVasmSJ+vfvrxUrVigkJKTKn+lwOGSz2WS32znfHw3KR2vSdd/8XxQR5K9v/zlC0REn/rEMAAAAQP1TnR7q0Yz/0aNHtXLlSmVkZJx0TEZGhlauXKljx4558hEe+emnn/Tbb79pwIABJy39khQWFqYVK1bonnvu0aZNm/Tkk09q8+bNmjJlipYuXVqt0g80VNkFxXp88RZJ0p2jO1L6AQAAAB/lUfF/5plnNHLkSO3bt++kY/bt26eRI0fqhRde8DhcdQ0YMECGYWj16tWnHWuz2TR37lzt2bNHRUVF2r17t5544glFRETUQVLAfM8v26ZDOYWKbxaqCYMTTv8CAAAAAA2SR8X/yy+/VPv27dWvX7+TjunXr58SEhL0+eefexwOQO3YfThXb3y/S5L073HdFOhfo+U+AAAAANRjHv22v2vXLnXu3Pm047p06aKdO3d68hEAatGjX2xSkdOloYnNNbprC7PjAAAAAKhFHhX/8kUETicyMrJOz/EHcHo/bD+kJRsPyGqRpnP5PgAAAMDneVT8o6OjtXnz5tOO27Jli6Kiojz5CAC1wOky9MjnmyRJV5/VVp1asqYFAAAA4Os8Kv4DBw5UamqqVq5cedIx3333ndavX6+BAwd6HA6Ad81fu1cb9zkUEeyvSWd3MjsOAAAAgDrgUfG/7bbbZBiGLr/8ci1YsOCE/QsWLNDll18ui8WiW2+9tcYhAdRcbmGJ/m9J2eX7RnVUs3Au3wcAAAA0Bv6evGjUqFG644479Pzzz+vSSy9V8+bN3Yv9bd26VVlZWTIMQ7fddpvGjBnj1cAAPPPSiu3Kyi5Uu2ahum5wvNlxAAAAANQRj4q/JD377LNKTEzUrFmzlJWVpaysLPe+5s2b61//+pfuvvtur4QEUDMZx/L1ysodkqRp53VRkL+fyYkAAAAA1BWLYRhGTd7A6XRq7dq12r17tySpbdu26tevn/z8Gk+xKL/Kgd1uV2RkpNlxgBPc/cF6LUjN1ICEKH1480BW8gcAAAAauOr0UI9n/Mv5+flpwIABGjBgQE3fCkAtWL/nqBakZspikaaP4/J9AAAAQGPj0eJ+ABoGwzD0yBell++7tHcb9WhjMzkRAAAAgLpWoxn/zMxMLVu2TBkZGSooKKh0jMVi0fTp02vyMQA89Pkv+7R291GFBPjpvrGdzY4DAAAAwAQeF//Jkyfr+eefl9PplFQ6s3g8i8UiwzAo/oBJCoqdmr1osyTp1uEd1DIy2OREAAAAAMzgUfF/6qmn9PTTT8tisejcc89V165dWdQOqGdeT9mpjGP5ahUZrJuHtTc7DgAAAACTeFT8X3vtNfn7+2vJkiUaMWKElyMBqKms7EL9v2XbJUn3je2skMDGc5UNAAAAABV5tLjf9u3bNWTIEEo/UE899fUW5RSWqGcbmy7u1drsOAAAAABM5FHxj4iIUExMjLezAPCCTfsc+nBNuiRp+vndZLVy+T4AAACgMfOo+A8dOlQbNmzwdhYANVR6+b6NchnSuB4x6h8fZXYkAAAAACbzqPg/+OCD2rZtm5KTk72dB0ANfLv5oFK2HVagn1VTz+tidhwAAAAA9YBHi/s5HA5NnjxZt9xyi5YsWaLzzz9fbdu2ldVa+d8Rhg0bVqOQAE6v2OnSo19ukiTdMCRBcVGhJicCAAAAUB9YDMMwqvsiq9Uqi8UiwzBksZz6/GGLxaKSkhKPAzYEDodDNptNdrudyxrCNG/9sEszFv6uZmGBWnbvCEUGB5gdCQAAAEAtqU4P9WjGf9iwYact/ADqjqOgWE9/s1WSdM85nSj9AAAAANw8Kv7Lly/3cgwANfHCsm06mlesDtFhGt8/zuw4AAAAAOoRjxb3A1B/pB/J0xvf75IkPfCXrvL343/WAAAAAP5AQwAauMcXb1GR06XBHZppVJcWZscBAAAAUM94dKj/8XJzc7Vt2zY5HA6dbJ1AVvUHasf6PUf1vw2Zslikf43rytobAAAAAE7gcfHfsWOH7r77bn311VdyuVwnHdcYVvUHzGAYhh75ovTyfZf1aaMzYm0mJwIAAABQH3lU/Pft26dBgwYpKytLsbGxKikp0cGDBzVo0CClpaXp0KFDslgsGjRokAICWF0cqA2LftuvtbuPKiTAT/8c09nsOAAAAADqKY/O8Z89e7aysrL0wAMPaO/evTrvvPNksViUkpKigwcPatGiRWrXrp1CQkL09ddfezsz0OgVljg1e9FmSdJNw9qrlS3Y5EQAAAAA6iuPiv/ixYvVunVrPfTQQ5XuP/fcc7Vo0SKtXLlSTz75ZI0CAjjRvFW7tedInqIjgnTLsPZmxwEAAABQj3lU/Pfs2aNevXrJz8+v9E2spW9z/Ln8nTt31tChQ/Xee+95ISaAckdzi/Ts0jRJ0j/HdFJYUI3X6AQAAADgwzwq/gEBAQoLC3M/L3986NChCuNatGihHTt21CAegD979ts0OQpK1KVVhC7vG2d2HAAAAAD1nEfFPzY2Vunp6e7nCQkJkqSff/65wrjff/9doaGhNYgH4Hg7D+Vq3qrdkqQH/tJVflYu3wcAAADg1Dwq/n379tWmTZvch/aPHj1ahmFo6tSp+v3335Wdna3//Oc/+vXXX3XmmWd6NTDQmM1ZtFklLkPDO0VrWKdos+MAAAAAaAA8Kv5jx47VsWPH9NVXX0mSevbsqYsvvlgbN25Uz5491aRJE02fPl1Wq1UzZszwamCgsfpp5xF99ft+WS3Sv8Z1NTsOAAAAgAbCo+J/1VVXKT09XSNGjHBve+edd3THHXeoRYsW8vf3V48ePfTf//5XSUlJ3soKNFoul6FHv9goSbqyf1t1ahlhciIAAAAADYXFMAzD7BANncPhkM1mk91uV2RkpNlx4IMWpGbo7g9SFRbop+X3jlR0RJDZkQAAAACYqDo91KMZfwB1p6DYqce/2iJJum1EB0o/AAAAgGqh+AP13Fs/7FLGsXy1igzWjUPamx0HAAAAQAPjX5VBDz/8sCTpjjvuUFRUlPt5VVgsFk2fPt2zdEAjdzS3SM8v2yZJmjKmk0IC/UxOBAAAAKChqdI5/larVRaLRZs2bVKnTp3cz0/10vL9FotFTqfTq6HrG87xR2155PONSv5+p7q0itAXdw2Vn9VidiQAAAAA9UB1emiVZvwffPBBWSwWNW/evMJzALUn/Uie3l61W5I09bwulH4AAAAAHmFVfy9gxh+14a7312vhhkwN6dhc824cwB/bAAAAALjV+qr+K1euVEpKikfhAJzeL3uPaeGGTFkspbP9lH4AAAAAnvKo+I8YMYIF+4BaYhiGHv1ikyTpkl6t1b21zeREAAAAABoyj4p/06ZNFRsb6+0sACR9u/mgVu88okB/qyaP6WR2HAAAAAANnEfFv1evXkpLS/N2FqDRK3G6NHvRZknS9UnxatM01OREAAAAABo6j4r/XXfdpTVr1uiLL77wdh6gUft47V6lHcxRk9AA3T6io9lxAAAAAPiAKl3O78969+6tO+64Q5dccokmTJigyy67TPHx8QoJCal0fNu2bWsUEmgM8opK9NTXWyVJd45KlC0kwOREAAAAAHyBR5fz8/Pzk1S6CNnpVhu3WCwqKSnxLF0DweX84A3PLk3TU19vVVxUiL6ZPFxB/n5mRwIAAABQT1Wnh3o04x8XF8flxQAvysou1MsrtkuS7ju3C6UfAAAAgNd4VPx37drl5RhA4/bM0q3KLXLqzDY2nd8zxuw4AAAAAHyIR4v7AfCe7Vk5ev+ndEnStL905WgaAAAAAF5F8QdMNmfRZjldhs7u2kID2zczOw4AAAAAH+OV4m+325Wenq49e/ZUeqtLn376qc455xw1a9ZMwcHBSkhI0Pjx45Wenl5hnMPh0OTJk9WuXTsFBQUpPj5e9957r3Jycuo0Lxq3NbuOaMnGA7JapKnndTE7DgAAAAAf5NE5/pJ09OhRPfjgg/rvf/+rrKysk46rq1X9DcPQrbfeqldeeUUdOnTQVVddpYiICGVmZmrFihXavXu34uLiJEm5ubkaPny4UlNTNWbMGI0fP17r16/XE088oRUrVmjlypUKDg6u9cxo3AzD0H++3CRJurJ/W3VsEWFyIgAAAAC+yKPib7fbNXDgQG3btk1+fn4KCQlRXl6eYmJitH//fvdl/tq2bevtvCf17LPP6pVXXtHtt9+uZ5991n3JwXLH//Hh8ccfV2pqqu6//37Nnj3bvX3q1KmaM2eO5s6dq2nTptVZdjROSzYe0Po9xxQS4KdJZyeaHQcAAACAj/LoUP//+7//U1pamq699lrZ7XZdfvnlslgsysjIUHZ2tl588UU1adJEw4cP186dO72d+QT5+fl66KGH1L59ez3zzDMnlH5J8vcv/RuHYRhKTk5WeHi4pk+fXmHM9OnTFR4eruTk5FrPjMbN6TL0xOItkqQbhsSrRSRHmAAAAACoHR7N+C9cuFDNmzfXiy++qODg4AqrkIeGhuqWW27RmWeeqSFDhmjw4MG6+eabvRa4MkuWLNHRo0d1/fXXy+l0auHChdq6dauaNGmis88+Wx07dnSPTUtLU2Zmps4991yFhYVVeJ+wsDAlJSVp8eLFSk9Pd58aAHjbZ+szlHYwR7aQAN08rIPZcQAAAAD4MI+K/44dOzR06FD3efDlxd/pdLpn2wcOHKhBgwbptddeq/Xiv3btWkmSn5+fevbsqa1bt7r3Wa1WTZo0SU888YSk0uIvSYmJlR9anZiYqMWLFystLe2kxb+wsFCFhYXu5w6HwyvfA41DUYlLc78p/Rm9dXgH2UICTE4EAAAAwJd5vKp/06ZN3Y9DQ0MllS74d7y2bdtq8+bNnn5ElR08eFCS9NRTT8lms+mnn35Sdna2Vq5cqU6dOunJJ5/Uiy++KKl0fQJJstlslb5XZGRkhXGVeeyxx2Sz2dw3jgxAdbz/0x7tPZqvFhFBmjA43uw4AAAAAHycR8U/NjZWGRkZ7ufli/j98ssvFcbt2LHDfW59bXK5XJKkwMBAffbZZ+rfv7/Cw8M1dOhQ/fe//5XVatWTTz7ptc+bNm2a7Ha7+/bnSwUCJ5NXVKLnvt0mSbprdKJCAk9cjwIAAAAAvMmj4t+jRw9t2bLF/Xzo0KEyDEMzZsxQdna2JOmdd97R6tWr1a1bN+8kPYXy2ft+/fopNja2wr7u3burffv22r59u44dO+Yee7IZ/fLD9k92RIAkBQUFKTIyssINqIo3UnbpUE6h2jUL1ZX9OVIEAAAAQO3zqPiPHTtWBw8e1LJlyyRJgwYNUlJSklJSUhQVFaVmzZrpuuuuk8Vi0X333efVwJXp3LmzJKlJkyaV7i/fnp+f7z63v/xc/z873RoAgKeO5RXppRXbJUmTz+mkAD+Pz7QBAAAAgCrzqHmMHz9e3333nTp16uTe9sknn+j888+XVHquf5MmTfTUU0/pggsu8E7SUxg5cqQkadOmTSfsKy4u1rZt2xQWFqbo6GglJiYqNjZWKSkpys3NrTA2NzdXKSkpSkhI4Lx9eN2LK7Yru6BEXVpF6IKesad/AQAAAAB4gUfFPzw8XElJSWrdurV7W3R0tBYuXCi73a6MjAxlZWXp7rvv9lrQU+nQoYPGjBmjbdu2KTk5ucK+2bNn69ixY7rkkkvk7+8vi8WiiRMnKicnR7NmzaowdtasWcrJydFNN91UJ7nReBxwFOjNlF2SpHvP7Syr1XLqFwAAAACAl1gMwzDMDuEN27dv1+DBg3Xw4EGNGzdOXbp00fr16/Xtt9+qXbt2+vHHH9WqVStJpTP7SUlJ2rBhg8aMGaM+ffpo3bp1WrJkifr3768VK1YoJCSkyp/tcDhks9lkt9s53x+V+tenv+rd1XvUt11TfXzrIPclMAEAAADAE9XpoR7N+F922WX68ssv3avp1wcdOnTQzz//rAkTJmjt2rV69tlnlZaWpn/84x/66aef3KVfksLCwrRixQrdc8892rRpk5588klt3rxZU6ZM0dKlS6tV+oHT2X04Vx+uKb3yw33ndqb0AwAAAKhTHs34W61WWSwWtWzZUtdee62uv/569wJ7jREz/jiVuz9YrwWpmRreKVpv3TDA7DgAAAAAfECtz/g/++yz6tWrl/bv36/HH39c3bp1U1JSkpKTk92X8wMgbcx0aOGGTEml5/YDAAAAQF3zqPjfcccdWrt2rTZs2KC7775bzZs316pVq3TLLbcoJiZG1113nftSf0Bj9sSSLTIM6fyeMere2mZ2HAAAAACNUI0uJN6jRw/NnTtXGRkZmj9/vsaNG6eioiLNmzdPZ599tjp06HDCyvlAY/HzriP6dvNB+VktmjKG2X4AAAAA5vD6qv4HDx7UO++8ozfeeEO///67LBaLnE6nNz+i3uEcf/yZYRi68uUf9dOuIxo/IE6PXdrT7EgAAAAAfEitn+N/KjabTTExMRVW0Qcam+Vbs/TTriMK9LfqrtGJZscBAAAA0Ij5e+uNfvzxR7355pv68MMP5XA4ZBiGmjZtqvHjx3vrI4AGweUy9MTiLZKk6wa1U4yNy0MCAAAAME+Niv++ffv09ttv66233tKWLVtkGIasVqvOPvts3XDDDbr44osVFBTkraxAg/DV7/v1e6ZD4UH+um1ER7PjAAAAAGjkPCr+H330kd588019/fXXcrlcMgxD7du314QJE3TdddcpLi7O2zmBBsHpMvTU11slSTcOSVBUWKDJiQAAAAA0dh4V/6uuukqSFBoaqssuu0zXX3+9RowY4c1cQIO0cEOGth3MkS0kQDcOTTA7DgAAAAB4VvzPOuss3XDDDbrqqqsUERHh7UxAg1TsdOnpb9IkSbcMb6/I4ACTEwEAAACAh8V/1apV3s4BNHjz1+7V7sN5ah4eqAmD482OAwAAAACSauFyfkBjVFji1LNLS2f7bxvRUaGBXrtgBgAAAADUCMUf8IIPfkpXpr1ArSKD9bez2podBwAAAADcKP5ADeUXOfX8sm2SpDtGdVRwgJ/JiQAAAADgDxR/oIbe+XG3srIL1aZpiP7aj0tZAgAAAKhfKP5ADeQUlujFFdslSXeNTlSgP/+TAgAAAFC/0FKAGngzZaeO5BYpoXmYLu3d2uw4AAAAAHACij/gIXtesV5euUOSdM/ZifL3439OAAAAAOofmgrgoeTvdyi7oESdW0bogp6xZscBAAAAgEpV6WLjK1eurNGHDBs2rEavB+qbwzmFev37nZKkSed0ktVqMTkRAAAAAFSuSsV/xIgRslg8KzYWi0UlJSUevRaor15euUO5RU51bx2pc89oaXYcAAAAADipKhX/YcOGnVD8i4qKtGrVKkmSzWZTfHy8JGn37t06duyYLBaLBg4cqMDAQO8mBkx20FGgt37YJUmaMqazx38UAwAAAIC6UKXiv3z58grPCwoKNHr0aHXo0EFPPPGELrroogr7Fy5cqHvvvVeStGjRIu8kBeqJF5ZtU2GJS33bNdWITtFmxwEAAACAU/Jocb9HHnlEGzZs0LJly04o/ZJ04YUX6ptvvtGGDRs0a9asGocE6ou9R/P03k97JElTzunEbD8AAACAes+j4v/RRx9p5MiRatOmzUnHxMXFadSoUfroo488DgfUN89/u03FTkOD2jfT4I7NzY4DAAAAAKflUfFPT09XWFjYaceFhoZq7969nnwEUO/sOZyn/64t/XmeMqaTyWkAAAAAoGo8Kv5NmzbV999/r6KiopOOKSoq0vfff6+mTZt6HA6oT55fliany9CwTtHqFx9ldhwAAAAAqBKPiv/YsWO1b98+TZgwQUePHj1h/7Fjx3T99ddr3759Ou+882ocEjDbnsN5+mRdhiTp7tGJJqcBAAAAgKqzGIZhVPdFe/fuVd++fXXo0CGFhYVp7NixSkhIkCTt2rVLX331lXJychQdHa2ff/75lGsB+AKHwyGbzSa73a7IyEiz46AW3P/xL/rw53QNTWyueTeeZXYcAAAAAI1cdXpolS7n92dt2rTRihUrdO211+rnn3/Wxx9/7F7dvPzvCH369NG8efN8vvTD96UfydP8daXn9t9zNrP9AAAAABoWj4q/JHXp0kU//fSTfvjhBy1fvty9iF/r1q01fPhwDRkyxGshATP9v+XbVOIyNDSxufq249x+AAAAAA2Lx8W/3ODBgzV48GBvZAHqnb1H8/Tfn0v/qMW5/QAAAAAaIo8W9wMaixeWbVeJy1BSx2as5A8AAACgQapR8f/uu+/017/+VW3atFFQUJBuvPFG976vv/5aDzzwgPbv31/jkIAZMo7l6+O16ZKku0d3MjkNAAAAAHjG4+L/yCOPaMSIEfr444+VmZmp4uJiHX+BAJvNpjlz5uiTTz7xSlCgrv2/ZdtU7DQ0uEMzDUhgth8AAABAw+RR8V+0aJEefPBBtW7dWh999JEOHDhwwpgBAwYoOjpan3/+eY1DAnUt41i+Pvq5fLafc/sBAAAANFweLe73zDPPKCgoSIsWLdIZZ5xx0nFnnnmm0tLSPA4HmOXF5aWz/QPbR+ms9s3MjgMAAAAAHvNoxn/NmjUaMGDAKUu/JEVHR3OOPxqcffZ8fbSmfCV/zu0HAAAA0LB5VPxzc3PVqlWr046z2+1yuVyefARgmheXb1eR06WzEqI0qAOz/QAAAAAaNo+Kf8uWLbVt27bTjtuyZYvi4uI8+QjAFPvs+frgp7Jz+8/m3H4AAAAADZ9HxX/IkCFKTU1VSkrKScd8/vnn2rZtm0aOHOlxOKCuvVQ22z8gPkqDOLcfAAAAgA/wqPhPmTJFFotFl156qT777DOVlJRU2P/VV19p4sSJCggI0J133umVoEBt228v0PtrSmf77zk7URaLxeREAAAAAFBzHhX/Pn366Mknn9ShQ4d02WWXqUmTJrJYLJo/f76aNGmicePG6eDBg3ryySfVrVs3b2cGasVLK7arqMSl/vFNObcfAAAAgM/wqPhL0t13360vv/xS/fv3V35+vgzDUHZ2thwOh3r06KGFCxfqjjvu8GZWoNYccBTovZ/2SCpdyZ/ZfgAAAAC+wr8mLz733HN17rnn6vDhw9q5c6dcLpfi4uIUExPjrXxAnSif7e/XrqmSOjLbDwAAAMB31Kj4l2vWrJmaNaMsoWE6mF2g91aXzfZzbj8AAAAAH+Pxof6Ar3h5xQ4VlrjUp20TDenY3Ow4AAAAAOBVNZrxX716tb755htlZGSooKCg0jEWi0WvvfZaTT4GqDVZ2YV6d/VuSdLdZ3NuPwAAAADf41HxLyoq0vjx4/XZZ59JkgzDOOlYij/qs1e/26GCYpfOjGuiYYnM9gMAAADwPR4V/1mzZunTTz9VWFiYrrnmGnXt2lWRkZHezgbUqkM5hZq3qnS2/57RnNsPAAAAwDd5VPzff/99hYaGavXq1erWrZu3MwF1Ivm7ncovdqpnG5tGdI42Ow4AAAAA1AqPFvfbu3evkpKSKP1osI7kFuntVbskSXeNYrYfAAAAgO/yqPg3bdpUUVFR3s4C1Jnk73Yor8ip7q0jNbprC7PjAAAAAECt8aj4n3322Vq9evUpF/Wra/Hx8bJYLJXeRowYccL4wsJCPfzww0pMTFRwcLBiY2N188036+DBg3UfHnXqWF6R3vphlyRm+wEAAAD4Po8X9+vVq5dmzpyphx56yNuZPGaz2XTPPfecsD0+Pr7Cc5fLpYsuukiLFy/WwIEDddlllyktLU3JyclaunSpfvzxR0VHc863r3rt+53KLXKqa0ykzunW0uw4AAAAAFCrPCr+K1eu1PXXX69HHnlEX331lcaNG6e2bdvKaq38AIJrr722RiGrqkmTJpo5c+Zpx7311ltavHixxo8fr3fffdc94/vSSy/ptttu07///W+9/PLLtZwWZrDnFevNlF2SpLtHd2S2HwAAAIDPsxgeHK9vtVplsVjch/qfrjw5nU7P0lVD+az+rl27Tjt28ODBWrVqlXbt2qV27dq5txuGoY4dO+rAgQPKyspSSEhIlT7b4XDIZrPJbrdzWcN6bu7XW/XM0jR1aRWhL+8aKquV4g8AAACg4alOD/Voxv/aa6+tlzOlhYWFevPNN5WZmanIyEj1799fZ511VoUxBQUFWr16tTp37lyh9Eulf8A455xz9PLLL+vnn3/W0KFD6zI+apk9v1ivp+yUJN05KpHSDwAAAKBR8Kj4v/nmm16O4R379+/X9ddfX2Fb//799f7776tDhw6SpO3bt8vlcikxMbHS9yjfnpaWdtLiX1hYqMLCQvdzh8PhjfioZW/9sEvZBSVKbBGu87q3MjsOAAAAANQJj1b1r4+uv/56LV26VAcOHFBubq7Wr1+va665RmvWrNHo0aOVnZ0tSbLb7ZJKFwKsTPkhEuXjKvPYY4/JZrO5b3FxcV7+NvC27IJivfZ92Wz/aGb7AQAAADQePlP8Z8yYoVGjRqlFixYKDQ1Vr1699Pbbb+uaa67R7t279eqrr3rts6ZNmya73e6+paene+29UTve+mGX7PnF6hAdpnE9YsyOAwAAAAB1pkqH+q9cuVKSNGDAAAUHB7ufV9WwYcOqn8xLbrnlFs2bN08pKSmaPHmye6b/ZDP65Yftn+yIAEkKCgpSUFCQ98OiVuQUlii5bLb/rtGJ8mO2HwAAAEAjUqXiP2LECFksFm3atEmdOnVyP68Ki8WikpKSGoWsiebNm0uScnNzJUnt27eX1WpVWlpapePLt59sDQA0PG+v2qVjecVq3zxM5/eMNTsOAAAAANSpKhX/YcOGyWKxKDQ0tMLzhmD16tWS/rjcX0hIiAYMGKAff/xRu3fvPuFyfl9//bXCwsLUr18/M+LCy3ILS/Tqyh2SpDtGdWS2HwAAAECjU6Xiv3z58lM+N9vmzZvVtm1b9x8mjt9+//33S5Kuvvpq9/abb75ZP/74o6ZNm6Z3333X/UeMl19+WTt27NDNN9+skJCQuvsCqDXv/LhbR/OKFd8sVBeeyWw/AAAAgMbHo8v51TcffPCBnnrqKQ0bNkzt2rVTWFiYtm7dqi+//FLFxcWaNm1ahXUGrrvuOn344Yd6//33tXPnTg0fPlzbtm3TJ598ooSEBD3yyCMmfht4S36RU6+Uzfb/Y2RH+fv5zFqWAAAAAFBlPlH8R44cqU2bNmn9+vX67rvvlJeXp+bNm+svf/mLbr/9do0ZM6bCeKvVqgULFmj27NmaN2+e5s6dq6ioKN1444165JFHFB0dbdI3gTe999MeHc4tUtuoUF3cu7XZcQAAAADAFBbDMIyavondbpfD4dDJ3qpt27Y1/Yh6zeFwyGazyW63KzIy0uw4kFRY4tSwx5fpgKNQj13aQ+MH+PbPIAAAAIDGpTo91OMZ/6NHj+rBBx/Uf//7X2VlZZ10nNmr+qNx+njtXh1wFKpVZLAu7cNsPwAAAIDGy6Pib7fbNXDgQG3btk1+fn4KCQlRXl6eYmJitH//fhmGIYvF4vMz/aifSpwuvbRiuyTpluHtFeTvZ3IiAAAAADCPR6ud/d///Z/S0tJ07bXXym636/LLL5fFYlFGRoays7P14osvqkmTJho+fLh27tzp7czAKS3ckKn0I/lqFhaoq/rzxycAAAAAjZtHM/4LFy5U8+bN9eKLLyo4ONh9OTxJCg0N1S233KIzzzxTQ4YM0eDBg3XzzTd7LTBwKi6XoReWbZMk3Tg0QSGBzPYDAAAAaNw8mvHfsWOH+vbtq+DgYElyF3+n0+keM3DgQA0aNEivvfaaF2ICVfPV7/u1PStXkcH+umZgO7PjAAAAAIDpPL6wedOmTd2PQ0NDJZUu+He8tm3bavPmzZ5+BFAthvHHbP+EpARFBAeYnAgAAAAAzOdR8Y+NjVVGRob7efkifr/88kuFcTt27JC/v8cXDgCqZfmWLP2e6VBooJ+uHxxvdhwAAAAAqBc8Kv49evTQli1b3M+HDh0qwzA0Y8YMZWdnS5LeeecdrV69Wt26dfNOUuAUDMPQc9+mSZL+PrCdmoYFmpwIAAAAAOoHj4r/2LFjdfDgQS1btkySNGjQICUlJSklJUVRUVFq1qyZrrvuOlksFt13331eDQxUZtWOw1q355gC/a2aOCTB7DgAAAAAUG94VPzHjx+v7777Tp06dXJv++STT3T++edLKj3Xv0mTJnrqqad0wQUXeCcpcArl5/Zf2S9OLSKDTU4DAAAAAPWHRyfgh4eHKykpqcK26OhoLVy4UHl5ebLb7WrZsqWsVo/XDgSqbP2eo0rZdlj+VotuGd7e7DgAAAAAUK94feW90NBQ9yr/QF0on+2/pHdrtWnKzx4AAAAAHI8peTRoGzMd+mbTQVkt0m0jOpgdBwAAAADqnSrN+L/99ts1+pBrr722Rq8HTuaF5aWz/X/pEaP20eEmpwEAAACA+qdKxX/ChAmyWCwefwjFH7Vhe1aOvvx1nyTpHyM7mpwGAAAAAOqnKhX/a6+9tkbFH6gNLy7fLsOQzu7aUl1jIs2OAwAAAAD1UpWK/5tvvlnLMYDqST+Sp0/XZ0iS7hjFbD8AAAAAnAyL+6FBennldjldhoZ0bK5ecU3MjgMAAAAA9RbFHw3OQUeBPvp5ryRm+wEAAADgdGpU/Ddu3Khbb71VXbp0UXh4uMLCwtS5c2fdeuut+u2337yVEajgtZSdKipxqW+7pjorIcrsOAAAAABQr3lc/F944QX17t1br776qrZu3aq8vDzl5+crLS1Nr7zyivr27atnn33Wm1kB2fOL9e6PeyRJt4/owKKTAAAAAHAaHhX/RYsW6c4771RJSYkuvfRSLVy4UL/++qt+/fVX/e9//9Pll18up9OpSZMmadGiRd7OjEbs3dW7lVNYok4twzWycwuz4wAAAABAvVelVf3/7PHHH5fFYtEHH3ygK664osK+M844Q+PGjdPHH3+sv/71r3r88cd13nnneSUsGreCYqde/36XJOnW4R1ktTLbDwAAAACn49GM/9q1azVgwIATSv/xLr/8cp111llau3atx+GA481ft1eHcgrVukmILjgz1uw4AAAAANAgeFT8LRaLOnTocNpxHTpwDja8w+ky9MrKHZKkG4ckKMCPC1IAAAAAQFV41J569uyptLS0045LS0tTjx49PPkIoIJFv+3T7sN5ahIaoKsGxJkdBwAAAAAaDI+K/+TJk7VmzRp98MEHJx3z4Ycfas2aNZo0aZLH4QBJMgxDL63YLkm6blC8QgM9WpoCAAAAABoljxpU3759NWnSJP3973/Xxx9/rGuvvVYJCQmSpJ07d2revHn69NNPNWnSJPXv31979uyp8Pq2bdvWPDkajZRth/VbhkPBAVZdNzje7DgAAAAA0KBYDMMwqvsiPz8/SaUzsSc7h/9k+ywWi0pKSqr7kfWaw+GQzWaT3W5XZGSk2XF8zt+Sf1TKtsOaMDheMy88w+w4AAAAAGC66vRQj2b84+LiWLQPdeKXvceUsu2w/KwWTRyaYHYcAAAAAGhwPCr+u3bt8nIMoHLl5/ZfdGas2jQNNTkNAAAAADQ8XBMN9dbOQ7la9Nt+SdItw09/+UgAAAAAwIk8Kv5FRUVVHvvnhf2Aqnpl5Q4ZhjSqSwt1bhVhdhwAAAAAaJA8Kv6DBw/Wzp07Tztu4cKF6tOnjycfgUbuoKNA89fulSTdNoLZfgAAAADwlEfFf926derbt68++eSTSvc7nU5NmTJFl1xyiY4dO1aTfGikXk/ZpSKnS33bNVX/+Ciz4wAAAABAg+VR8Z82bZrsdruuuOIK3XPPPRUuz5eenq6hQ4fq6aefVtOmTfXZZ595KysaCUdBsd79cbck6VbO7QcAAACAGvGo+D/66KP64osvFBUVpeeee05DhgzR7t279fnnn6t379768ccfNXDgQK1fv17nn3++tzPDx7374x5lF5YosUW4RndpYXYcAAAAAGjQPLqcnySNHTtW69ev11VXXaUffvhBPXr0UG5uriTpn//8px577DH5+fl5LSgah4Jip15PKV0/4pbhHWS1WkxOBAAAAAANW40u59emTRu98847stlsysnJkSRdf/31evzxxyn98Mgn6zKUlV2oGFuwLjwz1uw4AAAAANDg1aj4L168WAMGDJDD4VC3bt3k5+enN954QzfccIPy8/O9lRGNhNNl6JWV2yVJE4e2V6B/jX48AQAAAADysPi7XC498MADGjdunA4dOqRJkyZpw4YNWrZsmWJjY/XWW2/prLPO0pYtW7ydFz7sm00HtOtwnmwhAbqqf5zZcQAAAADAJ3hU/EeOHKk5c+YoMjJSn332mZ544gn5+fkpKSlJqampGjNmjH777Tf169dP8+bN83Zm+Kj//rxXknRV/ziFBXm8/AQAAAAA4DgeFf/vvvtOffv21bp163ThhRdW2NesWTMtWrRIjzzyiAoKCnT99dd7JSh82+GcQi3fclCSdHnfNianAQAAAADf4VHxv+OOO5SSkqL4+PiTjnnggQe0dOlStWrVytNsaEQWpGaqxGWoZxubEltGmB0HAAAAAHyGR8dTP/vss1UaN2zYMKWmpnryEWhk5q8rPcz/sj7M9gMAAACAN9X6sunNmzev7Y9AA7d5v0O/ZzoU4GfhEn4AAAAA4GVVKv5vv/22fvjhh0r3ORwOFRQUVLrv/fff1+TJkz1Ph0Zh/trS2f5RXVqoaVigyWkAAAAAwLdUqfhPmDBBycnJle5r2rSp/vGPf1S6b8mSJXrmmWc8TwefV+J06dP1mZI4zB8AAAAAakOND/U3DEOGYXgjCxqhlWlZOpRTqKiwQI3o3MLsOAAAAADgc2r9HH/gVOavzZAkXdQrVoH+/DgCAAAAgLfRtGAae16xvt54QBKH+QMAAABAbaH4wzT/+yVTRU6XurSK0BmxkWbHAQAAAACfRPGHaeavK13N/7I+bWSxWExOAwAAAAC+ieIPU2zPytH6PcfkZ7Xoot6xZscBAAAAAJ/lX9WB27Zt09tvv12tfdu2bfM8mRfMmTNHU6dOlSStWrVKAwcOrLDf4XBo5syZmj9/vvbv36+YmBhdccUVmjFjhsLDw82I3Gh8UjbbPyyxuVpEBJucBgAAAAB8l8WowrX4rFarR4diG4Yhi8Uip9PpUbia+O2339SvXz/5+/srNzf3hOKfm5urIUOGKDU1VWPGjFHv3r21fv16LVmyRP3799fKlSsVHFy1QupwOGSz2WS32xUZybnqp+NyGRoy51tl2gv0/NW9dX5PZvwBAAAAoDqq00OrNOPftm3bBnUOdnFxsa677jr16tVLiYmJeuedd04Y8/jjjys1NVX333+/Zs+e7d4+depUzZkzR3PnztW0adPqMnajsWrHYWXaCxQZ7K+zu7Y0Ow4AAAAA+LQqFf9du3bVcgzvevTRR/X7779r3bp1evzxx0/YbxiGkpOTFR4erunTp1fYN336dL3wwgtKTk6m+NeS+WtLD/M//8xYBQf4mZwGAAAAAHybzy3ut27dOj366KOaMWOGunXrVumYtLQ0ZWZmKikpSWFhYRX2hYWFKSkpSTt27FB6enpdRG5UcgpLtOi3/ZJKV/MHAAAAANQunyr+hYWFuvbaa9WrVy/dd999Jx2XlpYmSUpMTKx0f/n28nGVfY7D4ahwQ9Us+nWf8oudSmgepj5tm5gdBwAAAAB8nk8V/wcffFBpaWl644035Od38kPI7Xa7JMlms1W6v3xhhPJxf/bYY4/JZrO5b3FxcTVM3njML1vN/7I+rRvUuhEAAAAA0FD5TPFftWqVnnjiCf373/9W9+7da/Wzpk2bJrvd7r5xSkDVpB/J0487jshikS7hMH8AAAAAqBNVWtyvvispKdF1112nnj17aurUqacdXz7Tf7IZ/fJD9092REBQUJCCgoI8TNt4fbIuQ5I0qH0ztW4SYnIaAAAAAGgcfKL45+TkuM/HDwwMrHTMoEGDJEmffvqpe9G/k53Df7o1AFB9hmHok/Xlh/kz2w8AAAAAdcUnin9QUJBuvPHGSvetXLlSaWlpuvDCCxUdHa34+HglJiYqNjZWKSkpys3NrbCyf25urlJSUpSQkMC5+1708+6j2n04T2GBfjqvRyuz4wAAAABAo+ETxT8kJETJycmV7pswYYLS0tI0bdo0DRw40L194sSJevjhhzVr1izNnj3bvX3WrFnKycnRAw88UOu5G5P5a0tn+8/rEaPQQJ/4sQMAAACABqHRNrD77rtPCxYs0Jw5c7R+/Xr16dNH69at05IlS9S/f3/dc889Zkf0GQXFTn3xyz5JHOYPAAAAAHXNZ1b1r66wsDCtWLFC99xzjzZt2qQnn3xSmzdv1pQpU7R06VKFhLD4nLd8vfGAsgtL1LpJiM5KiDI7DgAAAAA0KhbDMAyzQzR0DodDNptNdrtdkZGRZsepdyZ9mKpP12foluHtNe28rmbHAQAAAIAGrzo9tNHO+KNuuFyGVm7NkiSN6NTC5DQAAAAA0PhQ/FGrfs906HBukcIC/dS3XVOz4wAAAABAo0PxR61asfWgJGlwx+YK9OfHDQAAAADqGk0MtWr5lrLD/DtHm5wEAAAAABonij9qjT2vWOv2HJUkDUuk+AMAAACAGSj+qDUp2w/JZUgdosMUFxVqdhwAAAAAaJQo/qg1K9yH+bOaPwAAAACYheKPWmEYhlaUXcZveCcO8wcAAAAAs1D8USu2HMjWfkeBggOsGpAQZXYcAAAAAGi0KP6oFeWH+Q9s30zBAX4mpwEAAACAxovij1pRfpj/CA7zBwAAAABTUfzhdTmFJVqz64gkaTgL+wEAAACAqSj+8LpV2w+r2GmobVSo4ptxGT8AAAAAMBPFH163YutBSaWr+VssFpPTAAAAAEDjRvGHVxmGoeVlC/uN6Mz5/QAAAABgNoo/vGrHoVztPZqvQD+rBrZvZnYcAAAAAGj0KP7wqvLL+PVPaKqwIH+T0wAAAAAAKP7wqvLL+A3nMn4AAAAAUC9Q/OE1BcVO/bjjsCRpBJfxAwAAAIB6geIPr/lxx2EVlrgUYwtWYotws+MAAAAAAETxhxcdf5g/l/EDAAAAgPqB4g+v4fx+AAAAAKh/KP7wivQjedqRlSs/q0VJic3NjgMAAAAAKEPxh1csL5vt79u2qSKDA0xOAwAAAAAoR/GHV6zYUnaYf2cO8wcAAACA+oTijxorKnHph+2HJHF+PwAAAADUNxR/1NjPu48or8ip5uFB6hYTaXYcAAAAAMBxKP6osfLD/Id1ai6rlcv4AQAAAEB9QvFHjXEZPwAAAACovyj+qJH99gJt3p8ti0UamkjxBwAAAID6huKPGllZNtt/ZpsmigoLNDkNAAAAAODPKP6okeVbD0riMH8AAAAAqK8o/vBYidOl79LKLuPXmeIPAAAAAPURxR8eS00/puyCEjUJDdCZbZqYHQcAAAAAUAmKPzxWPts/pGNz+XEZPwAAAAColyj+8Nj69GOSpAEJUeYGAQAAAACcFMUfHjEMQxvKin+vuCamZgEAAAAAnBzFHx7ZeShX9vxiBfpb1aVVpNlxAAAAAAAnQfGHR1LLZvt7tLYp0J8fIwAAAACor2hs8Egqh/kDAAAAQINA8YdHKP4AAAAA0DBQ/FFtBcVObcx0SKL4AwAAAEB9R/FHtf2eaVeJy1Dz8EC1aRpidhwAAAAAwClQ/FFt6/cck1Q622+xWMwNAwAAAAA4JYo/qo3z+wEAAACg4aD4o9rKi3/vtk3NDQIAAAAAOC2KP6rlUE6h9h7Nl8Ui9WxjMzsOAAAAAOA0KP6oltSy8/s7RocrIjjA3DAAAAAAgNOi+KNa1qcflcT5/QAAAADQUFD8US3uhf3aNjE1BwAAAACgaij+qDKXy9Av6XZJzPgDAAAAQENB8UeVbc/KUXZhiUIC/NS5ZYTZcQAAAAAAVUDxR5WtLzvMv0cbm/z9+NEBAAAAgIbAJ9pbQUGBJk+erGHDhik2NlbBwcFq1aqVkpKS9MYbb6i4uPiE1zgcDk2ePFnt2rVTUFCQ4uPjde+99yonJ8eEb9AwlJ/f35vD/AEAAACgwfCJ4p+Tk6MXX3xRFotF48aN0+TJk3XJJZcoIyNDN9xwg84//3y5XC73+NzcXA0fPlxz585Vly5dNGnSJHXu3FlPPPGERo0apYKCAhO/Tf1Vfik/zu8HAAAAgIbD3+wA3hAVFSW73a7AwMAK20tKSnTOOedoyZIlWrRokcaNGydJevzxx5Wamqr7779fs2fPdo+fOnWq5syZo7lz52ratGl1+h3qu7yiEm3e75DEiv4AAAAA0JD4xIy/1Wo9ofRLkr+/vy655BJJ0rZt2yRJhmEoOTlZ4eHhmj59eoXx06dPV3h4uJKTk2s/dAPz6167XIbUMjJIMbYQs+MAAAAAAKrIJ4r/ybhcLn311VeSpO7du0uS0tLSlJmZqaSkJIWFhVUYHxYWpqSkJO3YsUPp6el1nrc+++P8/qbmBgEAAAAAVItPHOpfrqioSP/5z39kGIYOHz6spUuXavPmzbr++us1evRoSaXFX5ISExMrfY/ExEQtXrxYaWlpiouLq7Ps9V158ecwfwAAAABoWHyu+D/00EPu5xaLRf/85z/12GOPubfZ7XZJks1mq/Q9IiMjK4yrTGFhoQoLC93PHQ5HjXI3BO7iz8J+AAAAANCg+NSh/uHh4TIMQ06nU+np6XrhhReUnJysESNGeLWcP/bYY7LZbO6brx8ZcMBRoH32AlktUo/Wlf/BBAAAAABQP/lU8S9ntVrVpk0b3XbbbXrllVeUkpKiRx99VNIfM/0nm9Ev/wPByY4IkKRp06bJbre7b76+HsD6ssv4dWoZobAgnzpIBAAAAAB8ns+3uDFjxkiSli9fLumPc/vLz/X/s9OtASBJQUFBCgoK8mLK+m19+lFJUm/O7wcAAACABscnZ/yPl5mZKUkKCAiQVFroY2NjlZKSotzc3Apjc3NzlZKSooSEBJ8/fL86Ustm/FnRHwAAAAAaHp8o/hs3blReXt4J2/Py8jR58mRJ0l/+8hdJpQv+TZw4UTk5OZo1a1aF8bNmzVJOTo5uuumm2g/dQDhdhn7NKD0tghX9AQAAAKDh8YlD/T/66CM99dRTGjJkiOLj4xUZGamMjAwtWrRIhw8f1tChQzVp0iT3+Pvuu08LFizQnDlztH79evXp00fr1q3TkiVL1L9/f91zzz3mfZl6ZuuBbOUVORUe5K8O0eFmxwEAAAAAVJNPFP/zzz9fmZmZ+uGHH7Rq1Srl5OTIZrOpZ8+euuqqq3TDDTfI3/+PrxoWFqYVK1Zo5syZmj9/vpYtW6aYmBhNmTJFM2bMUEhIiInfpn4pv4xfzzY2+Vkt5oYBAAAAAFSbxTAMw+wQDZ3D4ZDNZpPdbldkZKTZcbzq/o9/0Yc/p+v2ER1039guZscBAAAAAKh6PdQnzvFH7Smf8e8V18TUHAAAAAAAz1D8cVLZBcXaejBbEgv7AQAAAEBDRfHHSf261y7DkFo3CVGLiGCz4wAAAAAAPEDxx0mtLz/Mn9l+AAAAAGiwKP44qfLz+3tzfj8AAAAANFgUf1TKMAwW9gMAAAAAH0DxR6Uy7QXKyi6Uv9Wi7q1tZscBAAAAAHiI4o9Krd9zVJLUNSZSwQF+JqcBAAAAAHiK4o9Kpe45JonD/AEAAACgoaP4o1Kc3w8AAAAAvoHijxMUO136NcMuiUv5AQAAAEBDR/HHCbbsz1ZhiUuRwf5KaBZmdhwAAAAAQA1Q/HGC9WWH+Z8Z10RWq8XcMAAAAACAGqH44wS/lx/mz/n9AAAAANDgUfxxgi0HsiVJXVpFmpwEAAAAAFBTFH9UYBiGtu4vLf6dW4WbnAYAAAAAUFMUf1Sw92i+coucCvSzqh0L+wEAAABAg0fxRwVbyw7zbx8dpgA/fjwAAAAAoKGj2aGC8vP7O7eKMDkJAAAAAMAbKP6ooPz8/k4tKf4AAAAA4Aso/qhgy4EcSVJnij8AAAAA+ASKP9xKnC5tP1hW/DnUHwAAAAB8AsUfbrsO56nI6VJooJ9aNwkxOw4AAAAAwAso/nArX9G/U8sIWa0Wk9MAAAAAALyB4g+3LWUL+3F+PwAAAAD4Doo/3Nwz/pzfDwAAAAA+g+IPty0HmPEHAAAAAF9D8YckqaDYqV2HciVJnVqFm5wGAAAAAOAtFH9IkrYdzJHLkJqGBig6PMjsOAAAAAAAL6H4Q1LFFf0tFlb0BwAAAABfQfGHpOPO72dhPwAAAADwKRR/SJK27v9jxh8AAAAA4Dso/pAkbT2QI4kZfwAAAADwNRR/KLugWBnH8iVJnVpQ/AEAAADAl1D84Z7tbxUZLFtogMlpAAAAAADeRPGHe0V/DvMHAAAAAN9D8Ye27Kf4AwAAAICvovjDPePPiv4AAAAA4Hso/vjjUH+KPwAAAAD4HIp/I3cop1CHcopksUgdW4SbHQcAAAAA4GUU/0Zua9n5/e2iQhUS6GdyGgAAAACAt1H8G7ktnN8PAAAAAD6N4t/IcSk/AAAAAPBtFP9GrvxSfsz4AwAAAIBvovg3YoZhaOuBHEnM+AMAAACAr6L4N2KZ9gLlFJYowM+i+GZhZscBAAAAANQCin8jVr6if/vm4Qr050cBAAAAAHwRba8R28LCfgAAAADg8yj+jVj5jD/FHwAAAAB8F8W/ESuf8WdFfwAAAADwXRT/RqrE6VLawbIV/Sn+AAAAAOCzKP6N1O4jeSoqcSkkwE9tmoaYHQcAAAAAUEso/o1U+fn9nVqGy2q1mJwGAAAAAFBbKP6NFOf3AwAAAEDj4BPFPyMjQ08//bTGjBmjtm3bKjAwUK1atdJll12m1atXV/oah8OhyZMnq127dgoKClJ8fLzuvfde5eTk1HF6c2zlUn4AAAAA0Cj4RPF/7rnnNGnSJO3YsUNjxozRlClTNGTIEC1YsECDBw/Whx9+WGF8bm6uhg8frrlz56pLly6aNGmSOnfurCeeeEKjRo1SQUGBSd+k7mzZz4w/AAAAADQG/mYH8IYBAwZo+fLlGj58eIXt3333nUaPHq3bbrtNF198sYKCgiRJjz/+uFJTU3X//fdr9uzZ7vFTp07VnDlzNHfuXE2bNq1Ov0NdKih2atfhPEnM+AMAAACAr7MYhmGYHaI2nXvuuVqyZInWrFmjfv36yTAMtWnTRg6HQ/v371dYWJh7bG5urlq1aqUWLVpo+/btVf4Mh8Mhm80mu92uyMjI2vgaXrUx06G/PPudbCEBSn3wHFksLO4HAAAAAA1JdXqoTxzqfyoBAQGSJH//0oMb0tLSlJmZqaSkpAqlX5LCwsKUlJSkHTt2KD09vc6z1hX3+f0tIyj9AAAAAODjfLr479mzR998841iYmLUo0cPSaXFX5ISExMrfU359vJxlSksLJTD4ahwa0i2sLAfAAAAADQaPlv8i4uLdc0116iwsFBz5syRn5+fJMlut0uSbDZbpa8rP0SifFxlHnvsMdlsNvctLi7Oy+lr19byhf0o/gAAAADg83yy+LtcLk2YMEErV67UTTfdpGuuucar7z9t2jTZ7Xb3raGdFrDluEP9AQAAAAC+zSdW9T+ey+XSDTfcoPfee09///vf9dJLL1XYXz7Tf7IZ/fLD9k92RIAkBQUFua8Q0NDkFJZo79F8SVKnluEmpwEAAAAA1DafKv4ul0vXX3+93n77bY0fP15vvvmmrNaKBzWc7hz+060B0NCVL+zXMjJITUIDTU4DAAAAAKhtPnOo//Gl/8orr9S8efPc5/UfLzExUbGxsUpJSVFubm6Ffbm5uUpJSVFCQkKDO2+/qtzn93OYPwAAAAA0Cj5R/MsP73/77bd1xRVX6J133qm09EuSxWLRxIkTlZOTo1mzZlXYN2vWLOXk5Oimm26qi9im4Px+AAAAAGhcfOJQ/4cfflhvvfWWwsPD1alTJz3yyCMnjLn44ovVq1cvSdJ9992nBQsWaM6cOVq/fr369OmjdevWacmSJerfv7/uueeeuv0Cdaj8UH9W9AcAAACAxsEniv+uXbskSTk5OXr00UcrHRMfH+8u/mFhYVqxYoVmzpyp+fPna9myZYqJidGUKVM0Y8YMhYSE1FHyurdlf44kZvwBAAAAoLGwGIZhmB2ioXM4HLLZbLLb7YqMjDQ7zkkdzilU30e+kSRtfPhchQb6xN99AAAAAKDRqU4P9Ylz/FE1Ww+Uzva3jQql9AMAAABAI0Hxb0TKz+/vzPn9AAAAANBoUPwbEVb0BwAAAIDGh+LfiLRpGqIz29jUvXX9XYcAAAAAAOBdLO7nBQ1lcT8AAAAAgG9gcT8AAAAAACCJ4g8AAAAAgE+j+AMAAAAA4MMo/gAAAAAA+DCKPwAAAAAAPoziDwAAAACAD6P4AwAAAADgwyj+AAAAAAD4MIo/AAAAAAA+jOIPAAAAAIAPo/gDAAAAAODDKP4AAAAAAPgwij8AAAAAAD6M4g8AAAAA+P/t3XlQVGfWBvCnW6ABWTQoAZQ97jsqLjQREgU17uiARsVlEjUaGWUi6jiCJhFx1HEyldEyRhmNJpOMS9xlXABFNALqTKKWuIERjUZDWASDcL4/8vWNnW5AI9LYPL8qq1Lve+6953bfU+TcrcmMsfEnIiIiIiIiMmNs/ImIiIiIiIjMGBt/IiIiIiIiIjPGxp+IiIiIiIjIjLHxJyIiIiIiIjJjbPyJiIiIiIiIzBgbfyIiIiIiIiIzxsafiIiIiIiIyIyx8SciIiIiIiIyY2z8iYiIiIiIiMwYG38iIiIiIiIiM2Zh6gTMgYgAAAoKCkycCREREREREdUHuv5T149WhY1/DSgsLAQAuLu7mzgTIiIiIiIiqk8KCwvh6OhYZYxKHuf0AFWpoqICeXl5sLe3h0qlqvXtFxQUwN3dHdevX4eDg0Otb5/oecA6Iaoaa4SoaqwRouqxTmqXiKCwsBBubm5Qq6t+ip9X/GuAWq1G8+bNTZ0GHBwcWGBE1WCdEFWNNUJUNdYIUfVYJ7Wnuiv9Ony5HxEREREREZEZY+NPREREREREZMbY+JsBjUaD2NhYaDQaU6dCVGexToiqxhohqhprhKh6rJO6iy/3IyIiIiIiIjJjvOJPREREREREZMbY+BMRERERERGZMTb+RERERERERGaMjT8RERERERGRGWPj/xw7deoUBg4ciEaNGqFhw4bo2bMnPv/8c1OnRVSrbty4gVWrViEkJAQeHh6wsrKCi4sLwsLCcPLkSaPLFBQUYPbs2fD09IRGo4GXlxfeeecdFBUV1XL2RKaTkJAAlUoFlUqFEydOGMyzTqg+2r59O/r16wcnJydYW1vD29sbo0ePxvXr1/XiWB9UH4kItm3bhuDgYLi6usLW1hatWrXClClTcOXKFYN41kndwrf6P6eOHDmC0NBQWFtbIyIiAvb29ti6dStycnKwfPlyREdHmzpFoloxd+5cJCQkwNfXF0FBQWjatCmys7OxY8cOiAi2bNmC8PBwJb64uBharRZnzpxBSEgIunTpgtOnTyMpKQndu3dHamoqrK2tTbhHRM/e119/jW7dusHCwgLFxcVIT09Hz549lXnWCdU3IoKpU6di7dq18PX1RWhoKOzt7ZGXl4eUlBRs3rwZWq0WAOuD6q/o6GisXLkSrq6uGDp0KBwcHHD27FkkJSXBzs4Ox48fR/v27QGwTuokoedOWVmZ+Pr6ikajkdOnTyvj+fn50rJlS7GyspJr166ZLkGiWrR161ZJTk42GE9NTRVLS0tp3LixlJaWKuMLFy4UABITE6MXHxMTIwBkyZIlzzxnIlP66aefxM/PT3r06CFjx44VAJKenq4Xwzqh+mbVqlUCQN566y15+PChwXxZWZny36wPqo9u3rwparVaPD09JT8/X29u5cqVAkAmTpyojLFO6h42/s+hAwcOGBSXTmJiogCQRYsWmSAzorolJCREAMipU6dERKSiokLc3NzEzs5OioqK9GKLiorEzs5OfHx8TJEqUa2JjY0VjUYj33zzjURGRho0/qwTqm/u378vjRs3Fh8fH70G3xjWB9VX6enpAkDGjBljMHfx4kUBIIMGDRIR1kldxWf8n0PJyckAgJCQEIO50NBQAEBKSkptpkRUJ1laWgIALCwsAADZ2dnIy8tDQEAAGjZsqBfbsGFDBAQE4MqVKwbPchKZi6ysLLz//vuIjY1F27ZtjcawTqi+SUpKwg8//IBhw4ahvLwc27Ztw9KlS7FmzRpcunRJL5b1QfVVixYtYGVlhbS0NBQUFOjN7d69GwDw6quvAmCd1FVs/J9D2dnZAH4uwF9zcXGBnZ2dEkNUX+Xm5uLgwYNwdXVFhw4dAFRdO4+Os37IHD148ADjx49H586dMWfOnErjWCdU32RmZgIAGjRogI4dOyIsLAzz5s3DtGnT0KpVK/zxj39UYlkfVF85OTlh6dKlyM3NRevWrTFt2jTExMSgf//+iImJwVtvvYUZM2YAYJ3UVRamToCe3I8//ggAcHR0NDrv4OCgxBDVR2VlZRg3bhwePHiAhIQENGjQAMDj1c6jcUTmZOHChcjOzkZmZqZSE8awTqi+uX37NgBg5cqV8PPzw1dffYU2bdrg9OnTePPNN7FixQr4+vpi2rRprA+q12bNmoVmzZrh97//PdasWaOMa7VajBkzRrnDknVSN/GKPxGZlYqKCkyYMAGpqal44403MG7cOFOnRGRy6enpWL58ORYsWKC8cZmIflZRUQEAsLKywo4dO9C9e3fY2dkhMDAQX3zxBdRqNVasWGHiLIlMb/HixRg7dizmz5+P69evo7CwEEePHkVpaSmCgoKwc+dOU6dIVWDj/xzSnT2r7CxZQUFBpWfYiMxZRUUFJk2ahC1btmDs2LF6Z6OBx6udR+OIzMHDhw8RGRmJjh07Yu7cudXGs06ovtEdy926dYObm5veXPv27eHj44PLly8jPz+f9UH11sGDBxEbG4sZM2Zg7ty5aN68Oezs7KDVarFr1y5YWloqPyfOOqmbeKv/c+jR52K6du2qN3fr1i0UFRXB39/fFKkRmUxFRQUmTpyIjRs3YvTo0UhMTIRarX9us7pnyqp7Jo3oeVRUVKQc21ZWVkZjevXqBQDYvn278tI/1gnVF61atQIANGrUyOi8brykpIR/R6je2rdvHwAgODjYYM7FxQWtW7fG6dOnUVRUxDqpo9j4P4f69OmD+Ph4JCUlISIiQm/uwIEDSgxRffFo0x8eHo5NmzYZfYa5RYsWcHNzQ1paGoqLi/XeNFtcXIy0tDR4e3vD3d29NtMneqY0Gg0mT55sdC41NRXZ2dkYMmQImjZtCi8vL9YJ1Tu6Rub8+fMGc2VlZbh06RIaNmyIpk2bwsXFhfVB9dJPP/0EALhz547R+Tt37kCtVsPS0pJ/R+oqU/+eID25srIy8fHxEY1GI6dPn1bG8/PzpWXLlmJlZSVXr141WX5Etam8vFz5LfJRo0ZV+xvMCxcuFAASExOjNx4TEyMAZMmSJc8yXaI6RVc76enpeuOsE6pvQkJCBIB89NFHeuOLFy8WADJ27FhljPVB9dGnn34qAKRdu3aSn5+vN7d69WoBIAEBAcoY66TuUYmImOKEAz2dI0eOIDQ0FNbW1oiIiIC9vT22bt2KnJwcLF++XHnGhsjcxcXFYdGiRbCzs0NUVJTyRtlHDRs2DJ07dwbw85nmgIAAnD17FiEhIfDz80NWVhaSkpLQvXt3pKSkwMbGppb3gsg0JkyYgH/+859IT09Hz549lXHWCdU3ly9fRu/evXH79m289tprym3Lhw8fhqenJ06cOAEXFxcArA+qn8rLy/HKK68gNTUVzs7OGDJkCBo1aoSsrCwcPnwYNjY2SE5OVh43Zp3UQaY+80C/3cmTJ6V///7i4OAgNjY24u/vL5999pmp0yKqVborllX927Bhg94y+fn58oc//EHc3d3F0tJSPDw8JDo6WgoKCkyzE0QmUtkVfxHWCdU/ubm5MmHCBHFxcRFLS0txd3eX6dOny3fffWcQy/qg+qi0tFTi4+OlS5cuYmtrKxYWFtKsWTMZO3asnDt3ziCedVK38Io/ERERERERkRnjz/kRERERERERmTE2/kRERERERERmjI0/ERERERERkRlj409ERERERERkxtj4ExEREREREZkxNv5EREREREREZoyNPxEREREREZEZY+NPREREREREZMbY+BMRkUl5eXlBpVJBpVLh3//+d6Vxffv2hUqlQmJiYu0l9xsEBQVBpVIhOTnZ1Kk8c7t27UJgYCAcHByU77A+7DcREdHzxsLUCRAREen86U9/wrBhw2BhwT9Pdd2ZM2cQFhaGiooKvPLKK3B1dYVKpYKLi4upUyMTCAoKQkpKCo4cOYKgoCBTp0NERL/C/7MiIqI6wdbWFhcvXsS6deswdepUU6dD1dixYwfKysowf/58vP/++6ZOh4iIiKrAW/2JiKhOiIqKAgAsXrwY9+/fN3E2VJ3c3FwAQIsWLUycCREREVWHjT8REdUJAwcORJ8+fXDz5k389a9/fezlJkyYUOWz/4mJiVCpVJgwYUKl4z/++CNmz54NLy8vWFtbo0WLFkhISEBFRQUA4MaNG5gyZQrc3d2h0WjQqlUr/P3vf682t5SUFISEhOCFF16Ara0t/P39sWnTpiqXOXToEEaMGAFXV1dYWVnB2dkZw4cPR3p6utF43bP1ALBhwwb06tULjo6OUKlUuHbtWrU5AsDDhw+xZs0a9O7dG46OjspnMHPmTNy4cUMvNi4uDiqVChs2bAAATJw4UcnhSW7xvn//PlatWgWtVovGjRtDo9HA09MTgwcPxpYtW4zGL126FH5+frC3t4etrS3atWuHBQsW4IcffjCIv3btGlQqFby8vFBRUYEPPvgAHTt2hK2tLVxdXTF16lTcu3cPAPDgwQO8++67aN26NWxsbODm5oaoqCgUFxcbrFe3/3FxccjJycH48ePh6uoKa2trtGzZEnFxcSgpKal0vw8cOIBBgwbB2dkZVlZWcHNzQ3h4ODIyMozGP/rOiDNnzmDEiBFo0qQJNBoN2rZtixUrVkBEKt3e0xxPW7duhVarhYODAxo2bIiAgADs3btXLz45ORkqlQopKSkAgODgYGUdv67LzMxMhIeHo3nz5rCysoKDgwN8fHwQFhaGL7/8stJ9ICKiGiBEREQm5OnpKQDk6NGjcuLECQEgDg4O8v333+vFvfrqqwJANmzYoDceGRlpdFxnw4YNAkAiIyONjg8dOlTatGkjzs7OEhYWJiEhIWJjYyMAZMaMGXLp0iVxcXERd3d3+d3vfifBwcHSoEEDASBLly412F6fPn0EgMycOVPUarW0bdtWIiIi5OWXXxa1Wi0AZPbs2UZzjY6OFgCiVqvF399fRo0aJT169BCVSiUNGjSQ9evXGywDQMlVrVaLVquV0aNHS48ePeTatWuVf/D/r7S0VPr27SsAxNraWgYMGCDh4eHi7u4uAKRJkyaSmZmpxG/fvl0iIyPF19dXAEhAQIBERkZKZGSkxMfHV7s9EZHc3Fxp27atABBbW1vp16+fRERESGBgoDg6Ooqnp6de/N27d6Vz587KsTFkyBAJCwuTJk2aCADx9vaWq1ev6i1z9epVASCenp4yevRosbGxkf79+8uwYcPE2dlZAEiXLl2kqKhItFqtst5BgwaJo6OjAJABAwYY5B4bGysAZPz48eLk5CQvvviijBo1SgYNGiQNGzZUPpOSkhKDZRcsWCAARKVSSUBAgIwePVrZrwYNGsjHH39ssIzueJo7d65YWVlJmzZtJCIiQvr06aMch1FRUUY/56c5nhYuXKjkGR4eLp06dVJy37ZtmxJ//vx5iYyMlBdffFEASGhoqHI8REZGytGjR0VE5ODBg2JpaSkApFOnTjJy5EgZPny4+Pv7i0ajkaFDhxrdByIiqhls/ImIyKQebfxFREaMGCEAZNasWXpxz6rxByCDBw+W4uJiZS4zM1MsLCyUxn3q1KlSVlamzO/YsUNpQh9dTuSXRg2ALFmyRG8uOTlZOamwf/9+vbm1a9cKAHnppZfk7NmzenMpKSlib28vVlZWcvHiRb053bYcHBwkPT3d6GdQlZiYGAEgvr6+es3zTz/9JJMnT1Ya6wcPHugtV93nXpny8nLp1q2bAJCQkBC5ffu23nxJSYns2bNHbyw8PFwASI8ePfROCBUWFsqAAQMEgPTu3VtvGV3jr9u3R0+CfP/999KiRQsBIB06dBB/f3+99V65ckUaN24sAOTYsWN669U1/rqTRvfv31fmrl+/Li1btlQa9Uft27dPObmSlJSkN7du3ToBIJaWlvL111/rzT16PK1Zs0Zv7tChQ0oTf/36db25pz2eGjVqJCdOnDC67y1btpRf0+V55MgRgzkRkeDgYAEgn3zyicFcfn7+bzp2iYjo8bHxJyIik/p143/hwgWxsLAQjUaj16w9q8bfzs5OvvvuO4PlhgwZIgDEw8PD6NXbDh06CABJSUnRG9c1QF26dDGaj+4qbL9+/ZSx8vJycXNzEwCSkZFhdLlly5YJAImOjtYb1zVqixcvNrpcVUpKSsTOzk4AyM6dOw3mi4uLlSu5mzdv1pv7rY2/7qSJq6urFBYWVhufk5MjarVaVCqVQQMrIvLtt9+KtbW1AJC0tDRl/NHG/9cnEkREVq5cqVzB/t///mcw//bbbwsAWbRokd64rvm1sbGRmzdvGiy3a9cu5UTMo8eN7vit7G6PQYMGCQB544039MZ1x9OIESOMLte/f38BIBs3blTGauJ4+uCDDwyWKS0tVe6GyM3NNZpnZY2/7g6Pe/fuGZ0nIqJni8/4ExFRndKqVStMmjQJDx48wJ///Odnvr2uXbvC2dnZYFz30rrg4GBYW1tXOp+Xl2d0vePHjzc6HhkZCQA4duwYysvLAQCnT59GXl4efH190bVrV6PL6Z6fP378uNH5kSNHGh2vSkZGBoqKivDCCy9g8ODBBvO2traIiIgAABw5cuSJ12/M/v37AQBjxoyBnZ1dtfGpqamoqKhAly5d0LFjR4P5Zs2aITQ0tNIcLSwsEBISYjCu+/48PDzQvn37Sucr+35DQkKM/nThoEGD4OTkhIKCAmRlZQH4+R0KaWlpAGDwrgmdyZMnV7oPAIx+PwDQpk0bANB7F0NNHE/GtqfRaODj42Owvcfh7+8PAHj99ddx7NgxPHz48ImWJyKip8PGn4iI6py4uDjY2tpi8+bN+O9///tMt+Xh4WF0XNeUVjZvb28PACgtLTU67+3tXeV4SUkJ7t69CwC4cuUKAODy5ct6L0Z79J+ucbpz547R9Xp5eRkdr4queassVwDw9fXVi31aOTk5AIDWrVs/VvzT5ujq6goLC8NfL35W3y/wy3fx7bffAgDu3r2rrKey5ar7nCvL08HBwSDPmjienmR7jyM+Ph5+fn7Yt28fAgMD4eDgAK1WiwULFuD8+fNPtC4iInpyhn8JiYiITMzV1RVRUVGIj4/HvHnzsGfPnt+8Lt2b+SujVld9Dry6+ach//82dl2OLi4uytXryjRp0sTouI2NTc0mZybqwvdbE54kz5o4nmr6c3FxcUFGRgZSUlJw8OBBpKWl4eTJk0hLS8OSJUsQHx+PmJiYGt0mERH9go0/ERHVSTExMVi7di327t2L1NTUSuOsrKwAAIWFhUbndVeYa9vVq1eNjut+Ys/a2hpOTk4AAHd3dwCAk5NTpT9L+Cw0a9YMQOW5Ar9cPdbFPi3dleQLFy48Vrxuu7o8jKnpHB9HVZ+Z7jtu3rw5gJ+/V41GgwcPHuDKlStGH1moyX0w1fFUHd1PPuoeMygtLUViYiKmT5+O+fPnY+TIkcqdD0REVLN4qz8REdVJjo6OmD9/PgBgzpw5lcbpGiVjtwuLCPbt2/dsEqzGJ598YnR848aNAACtVqvcgt69e3c0adIE586dwzfffFNrOXbr1g12dna4d+8edu7caTBfUlKCzz77DMDP7zqoCf379wcAfPrppyguLq42/uWXX4ZarcaZM2dw9uxZg/mbN28q7w2oqRwfR1JSEm7fvm0wvnfvXty9exf29vbK8/UWFhbQarUAUGkjvn79egA1sw+mOJ50J+Ce5Nl9a2trTJ06FR07dkRFRcUzf6yHiKg+Y+NPRER11vTp0+Hh4YGTJ08iPT3daEzfvn0BAJs2bcK5c+eU8bKyMsTExODUqVO1kuuvZWZmYtmyZXpjx44dw4cffggAmDVrljJuaWmJ2NhYiAiGDx+OY8eOGayvvLwchw8fxokTJ2osR2tra0yfPh0AEB0drXd3RFlZGaKionDr1i14e3v/ppcHGjNkyBB06dIFeXl5GDVqlPKeA53S0lK9kzUeHh4YNWoURARTpkzRiy8uLsabb76J0tJS9O7dG717966RHB9HSUkJpk2bhpKSEmUsLy8P0dHRAICpU6fqvRRSN7569WocOnRIb12JiYnYuXMnLC0tERUV9dS5meJ40t3dUNmJhuXLlyM3N9dg/MKFC8jOzgYAeHp61kguRERkiLf6ExFRnaXRaLB48WJMmDAB9+/fNxoTEBCAoUOH4ssvv0S3bt2g1WphY2ODrKwsFBQUICoqCn/7299qOXNg5syZmDdvHjZu3IiOHTsiLy8PR48eRUVFBaKiojBw4EC9+BkzZiA3Nxd/+ctfEBgYiHbt2uGll16CjY0Nbt26hTNnziA/Px+rV69Gz549ayzPRYsWISMjA4cOHUKbNm0QHBwMe3t7pKenIzc3F05OTvjiiy+UK7pPS61WY/v27QgNDcW+ffvg4eEBrVYLJycn3LhxA2fPnkWjRo2U2+UB4MMPP8SFCxdw8uRJ+Pr6Ijg4GBYWFkhJScGdO3fg7e2NzZs310h+j2v8+PHYvXs3fHx8EBgYiNLSUhw+fBjFxcXo1asXFi1apBc/YMAALFiwAO+99x769euHgIAAeHh44MKFC8jKykKDBg2wZs0atGvXrkbyq+3jKSwsDBs2bMCcOXNw8OBBODs7Q6VSYdKkSejduzfee+89vPPOO2jdujXatGkDGxsb5OXlKW/4Hz9+PPz8/Gpgz4mIyBhe8Sciojpt3Lhx6NChQ5Ux//rXv7BgwQK4uroiOTkZJ06cQGBgILKystC5c+faSfRXhg8fjv/85z9wcXHB3r178dVXX8HPzw+JiYlYtWqV0WWWLVuGtLQ0vP766ygqKsL+/fuxZ88e5OXlISgoCOvWrUN4eHiN5qnRaLB//3784x//QKdOnXD06FFs374dlpaWePvtt3H27NlKfxLut/L09ERGRgYSEhLQrl07pKenY9u2bcjJyUGfPn2QkJCgF+/k5ITjx48jPj4e3t7eSEpKwu7du9GkSRPMnz8fmZmZv+lXDZ6Gt7c3MjIyEBwcjNTUVBw4cACurq5YuHAhDh48aPRli++++y727duHAQMG4Pz58/j888+VOx+OHz+OSZMm1WiOtXk8vfbaa/joo4/Qvn17HD58GOvXr8fHH3+MixcvAvj55M3EiROVEzZbt27F1atX0a9fP2zfvr1OvYuAiMgcqaQmXzlLREREZMbi4uKwaNEixMbGIi4uztTpEBERPRZe8SciIiIiIiIyY2z8iYiIiIiIiMwYG38iIiIiIiIiM8Zn/ImIiIiIiIjMGK/4ExEREREREZkxNv5EREREREREZoyNPxEREREREZEZY+NPREREREREZMbY+BMRERERERGZMTb+RERERERERGaMjT8RERERERGRGWPjT0RERERERGTG2PgTERERERERmbH/A/xhXJq4MmmRAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(range(1, len(pca.explained_variance_ratio_)+1), np.cumsum(pca.explained_variance_ratio_ * 100))\n",
        "plt.xlabel(\"Number of components\", fontsize=16)\n",
        "plt.ylabel(\"Explained variance (%)\", fontsize = 16)\n",
        "plt.tick_params(labelsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Feature Projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "V_Oqv88874xC"
      },
      "outputs": [],
      "source": [
        "# Select 20 principal components with highest explained variance as seen above\n",
        "# change the number of principal components to optimize model\n",
        "explained_variances = pca.explained_variance_ratio_\n",
        "selected_pca_indices = explained_variances.argsort()[::-1][:27]\n",
        "Xtrain_pca_selected = Xtrain_pca[:, selected_pca_indices]\n",
        "\n",
        "# create new train, validation, and test datasets with selected features\n",
        "Xtrain_selected = Xtrain_encoded.iloc[:, selected_pca_indices]\n",
        "Xval_selected = Xval_encoded.iloc[:, selected_pca_indices]\n",
        "Xtest_selected = Xtest_encoded.iloc[:, selected_pca_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TQACpi6WLKc"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Machine Learning Approach\n",
        "Let's use the gradient boosting regression model to predict the price of a house."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model setup\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbr_model = GradientBoostingRegressor(learning_rate=0.1,\n",
        "                                      n_estimators=100,\n",
        "                                      subsample=0.8,\n",
        "                                      max_depth=10,\n",
        "                                      random_state=42,\n",
        "                                      max_features='auto')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8STXPBh0WQGT"
      },
      "source": [
        "## Neural Network Approach\n",
        "#### Suppose there is a linear relationship between the house price and the features\n",
        "We can implement non-linear regression in the model during optimization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "SW30DH8KP-Zj"
      },
      "outputs": [],
      "source": [
        "def reset_seeds():\n",
        "    os.environ['PYTHONHASHSEED']=str(2)\n",
        "    tf.random.set_seed(2)\n",
        "    np.random.seed(2)\n",
        "    random.seed(2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create the model with TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "PuBvBrbCYCCT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "reset_seeds()\n",
        "\n",
        "def polynomial_activation(x):\n",
        "  return tf.keras.backend.square(x)\n",
        "\n",
        "n_features = Xtrain_selected.shape[1]\n",
        "input = Input(shape=(n_features,))\n",
        "#dropout1 = Dropout(0.5)(input)\n",
        "hidden1 = Dense(units = n_features, \n",
        "                activation = polynomial_activation, \n",
        "                activity_regularizer = tf.keras.regularizers.L2(0.01))(input)\n",
        "#dropout2 = Dropout(0.5)(hidden1)\n",
        "hidden2 = Dense(units = n_features//2, \n",
        "                activation = 'linear',\n",
        "                activity_regularizer = tf.keras.regularizers.L2(0.01))(hidden1)\n",
        "hidden3 = Dense(units = n_features//4, \n",
        "                activation = 'linear',\n",
        "                activity_regularizer = tf.keras.regularizers.L2(0.01))(hidden2)\n",
        "hidden4 = Dense(units = n_features//4, \n",
        "                activation = polynomial_activation,\n",
        "                activity_regularizer = tf.keras.regularizers.L2(0.01))(hidden3)\n",
        "output = Dense(units=1, activation = 'linear')(hidden2)\n",
        "\n",
        "house = Model(inputs=input, outputs = output)\n",
        "house.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005, use_ema=True, ema_momentum=0.99), loss=tf.keras.losses.MSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq0T4bjMagma",
        "outputId": "c6ee6c39-bd18-480b-f4dd-f1a91e07f91e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 27)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 27)                756       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13)                364       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 14        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,134\n",
            "Trainable params: 1,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "house.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "GpgaQ86-aiC5",
        "outputId": "bf80151b-df15-4d5a-b7a5-71d281f040f3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.plot_model(house, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDmNeG33dRJD"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Machine Learning Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/Users/lin.yang/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=10, max_features=&#x27;auto&#x27;, random_state=42,\n",
              "                          subsample=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=10, max_features=&#x27;auto&#x27;, random_state=42,\n",
              "                          subsample=0.8)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "GradientBoostingRegressor(max_depth=10, max_features='auto', random_state=42,\n",
              "                          subsample=0.8)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gbr_model.fit(Xtrain_encoded, ytrain_encoded)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural Netork Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlncD9f1amQa",
        "outputId": "bd7c49eb-805c-4474-f6a1-fe3c6a8c622c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "19/19 [==============================] - 1s 15ms/step - loss: 5.0514 - val_loss: 1.6843\n",
            "Epoch 2/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.9354 - val_loss: 1.3107\n",
            "Epoch 3/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 2.1171 - val_loss: 1.1642\n",
            "Epoch 4/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.7925 - val_loss: 1.0701\n",
            "Epoch 5/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.5734 - val_loss: 0.9914\n",
            "Epoch 6/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.4462 - val_loss: 0.9136\n",
            "Epoch 7/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.3487 - val_loss: 0.8442\n",
            "Epoch 8/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.2689 - val_loss: 0.7886\n",
            "Epoch 9/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.1996 - val_loss: 0.7393\n",
            "Epoch 10/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 1.1447 - val_loss: 0.6942\n",
            "Epoch 11/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0878 - val_loss: 0.6629\n",
            "Epoch 12/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 1.0418 - val_loss: 0.6317\n",
            "Epoch 13/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 1.0020 - val_loss: 0.6057\n",
            "Epoch 14/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9643 - val_loss: 0.5782\n",
            "Epoch 15/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9315 - val_loss: 0.5545\n",
            "Epoch 16/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.9002 - val_loss: 0.5330\n",
            "Epoch 17/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8728 - val_loss: 0.5146\n",
            "Epoch 18/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8476 - val_loss: 0.4965\n",
            "Epoch 19/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.8239 - val_loss: 0.4823\n",
            "Epoch 20/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.8022 - val_loss: 0.4652\n",
            "Epoch 21/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7822 - val_loss: 0.4519\n",
            "Epoch 22/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.7632 - val_loss: 0.4387\n",
            "Epoch 23/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7450 - val_loss: 0.4259\n",
            "Epoch 24/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7282 - val_loss: 0.4143\n",
            "Epoch 25/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7141 - val_loss: 0.4022\n",
            "Epoch 26/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6978 - val_loss: 0.3917\n",
            "Epoch 27/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6838 - val_loss: 0.3820\n",
            "Epoch 28/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6706 - val_loss: 0.3707\n",
            "Epoch 29/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.6579 - val_loss: 0.3634\n",
            "Epoch 30/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6457 - val_loss: 0.3568\n",
            "Epoch 31/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6367 - val_loss: 0.3501\n",
            "Epoch 32/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6254 - val_loss: 0.3440\n",
            "Epoch 33/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6136 - val_loss: 0.3345\n",
            "Epoch 34/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6033 - val_loss: 0.3282\n",
            "Epoch 35/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5936 - val_loss: 0.3212\n",
            "Epoch 36/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5849 - val_loss: 0.3160\n",
            "Epoch 37/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5763 - val_loss: 0.3097\n",
            "Epoch 38/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.5672 - val_loss: 0.3058\n",
            "Epoch 39/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5584 - val_loss: 0.2993\n",
            "Epoch 40/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.5519 - val_loss: 0.2935\n",
            "Epoch 41/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5431 - val_loss: 0.2897\n",
            "Epoch 42/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5369 - val_loss: 0.2858\n",
            "Epoch 43/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5308 - val_loss: 0.2815\n",
            "Epoch 44/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5222 - val_loss: 0.2771\n",
            "Epoch 45/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5166 - val_loss: 0.2720\n",
            "Epoch 46/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5098 - val_loss: 0.2710\n",
            "Epoch 47/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5027 - val_loss: 0.2664\n",
            "Epoch 48/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4967 - val_loss: 0.2630\n",
            "Epoch 49/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4922 - val_loss: 0.2590\n",
            "Epoch 50/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4854 - val_loss: 0.2565\n",
            "Epoch 51/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4803 - val_loss: 0.2534\n",
            "Epoch 52/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4744 - val_loss: 0.2508\n",
            "Epoch 53/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4687 - val_loss: 0.2480\n",
            "Epoch 54/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4638 - val_loss: 0.2444\n",
            "Epoch 55/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4587 - val_loss: 0.2429\n",
            "Epoch 56/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4545 - val_loss: 0.2395\n",
            "Epoch 57/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4490 - val_loss: 0.2376\n",
            "Epoch 58/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4446 - val_loss: 0.2363\n",
            "Epoch 59/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.4411 - val_loss: 0.2331\n",
            "Epoch 60/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4356 - val_loss: 0.2295\n",
            "Epoch 61/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4305 - val_loss: 0.2308\n",
            "Epoch 62/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4252 - val_loss: 0.2273\n",
            "Epoch 63/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4221 - val_loss: 0.2250\n",
            "Epoch 64/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4166 - val_loss: 0.2239\n",
            "Epoch 65/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4123 - val_loss: 0.2215\n",
            "Epoch 66/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4080 - val_loss: 0.2213\n",
            "Epoch 67/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.4046 - val_loss: 0.2206\n",
            "Epoch 68/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4014 - val_loss: 0.2176\n",
            "Epoch 69/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3974 - val_loss: 0.2189\n",
            "Epoch 70/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3919 - val_loss: 0.2141\n",
            "Epoch 71/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3892 - val_loss: 0.2115\n",
            "Epoch 72/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3856 - val_loss: 0.2130\n",
            "Epoch 73/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3820 - val_loss: 0.2107\n",
            "Epoch 74/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3813 - val_loss: 0.2098\n",
            "Epoch 75/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3773 - val_loss: 0.2110\n",
            "Epoch 76/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3744 - val_loss: 0.2077\n",
            "Epoch 77/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3726 - val_loss: 0.2074\n",
            "Epoch 78/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3682 - val_loss: 0.2049\n",
            "Epoch 79/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3646 - val_loss: 0.2035\n",
            "Epoch 80/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3634 - val_loss: 0.2044\n",
            "Epoch 81/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3601 - val_loss: 0.2014\n",
            "Epoch 82/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3578 - val_loss: 0.2020\n",
            "Epoch 83/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3575 - val_loss: 0.1998\n",
            "Epoch 84/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3549 - val_loss: 0.1985\n",
            "Epoch 85/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3507 - val_loss: 0.1991\n",
            "Epoch 86/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3485 - val_loss: 0.1976\n",
            "Epoch 87/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3460 - val_loss: 0.1974\n",
            "Epoch 88/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3436 - val_loss: 0.1958\n",
            "Epoch 89/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3411 - val_loss: 0.1953\n",
            "Epoch 90/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3406 - val_loss: 0.1937\n",
            "Epoch 91/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3381 - val_loss: 0.1931\n",
            "Epoch 92/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3348 - val_loss: 0.1934\n",
            "Epoch 93/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3339 - val_loss: 0.1911\n",
            "Epoch 94/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3316 - val_loss: 0.1933\n",
            "Epoch 95/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.3317 - val_loss: 0.1926\n",
            "Epoch 96/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3287 - val_loss: 0.1921\n",
            "Epoch 97/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3262 - val_loss: 0.1889\n",
            "Epoch 98/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3242 - val_loss: 0.1900\n",
            "Epoch 99/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3220 - val_loss: 0.1879\n",
            "Epoch 100/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3206 - val_loss: 0.1898\n",
            "Epoch 101/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3208 - val_loss: 0.1882\n",
            "Epoch 102/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3170 - val_loss: 0.1856\n",
            "Epoch 103/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3154 - val_loss: 0.1893\n",
            "Epoch 104/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3162 - val_loss: 0.1880\n",
            "Epoch 105/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3139 - val_loss: 0.1855\n",
            "Epoch 106/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3183 - val_loss: 0.1889\n",
            "Epoch 107/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3083 - val_loss: 0.1837\n",
            "Epoch 108/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3059 - val_loss: 0.1885\n",
            "Epoch 109/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3049 - val_loss: 0.1838\n",
            "Epoch 110/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3038 - val_loss: 0.1850\n",
            "Epoch 111/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3012 - val_loss: 0.1845\n",
            "Epoch 112/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 0.1832\n",
            "Epoch 113/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2998 - val_loss: 0.1824\n",
            "Epoch 114/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2971 - val_loss: 0.1847\n",
            "Epoch 115/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2961 - val_loss: 0.1844\n",
            "Epoch 116/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2943 - val_loss: 0.1819\n",
            "Epoch 117/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2952 - val_loss: 0.1841\n",
            "Epoch 118/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2923 - val_loss: 0.1820\n",
            "Epoch 119/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2907 - val_loss: 0.1835\n",
            "Epoch 120/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2891 - val_loss: 0.1840\n",
            "Epoch 121/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2882 - val_loss: 0.1814\n",
            "Epoch 122/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2881 - val_loss: 0.1828\n",
            "Epoch 123/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2860 - val_loss: 0.1823\n",
            "Epoch 124/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2840 - val_loss: 0.1813\n",
            "Epoch 125/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2849 - val_loss: 0.1831\n",
            "Epoch 126/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2821 - val_loss: 0.1816\n",
            "Epoch 127/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2813 - val_loss: 0.1850\n",
            "Epoch 128/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2808 - val_loss: 0.1792\n",
            "Epoch 129/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2790 - val_loss: 0.1828\n",
            "Epoch 130/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2780 - val_loss: 0.1825\n",
            "Epoch 131/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2761 - val_loss: 0.1823\n",
            "Epoch 132/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2749 - val_loss: 0.1800\n",
            "Epoch 133/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2741 - val_loss: 0.1800\n",
            "Epoch 134/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2738 - val_loss: 0.1785\n",
            "Epoch 135/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2724 - val_loss: 0.1804\n",
            "Epoch 136/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2704 - val_loss: 0.1778\n",
            "Epoch 137/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2717 - val_loss: 0.1805\n",
            "Epoch 138/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2694 - val_loss: 0.1810\n",
            "Epoch 139/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2688 - val_loss: 0.1800\n",
            "Epoch 140/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2689 - val_loss: 0.1810\n",
            "Epoch 141/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2660 - val_loss: 0.1798\n",
            "Epoch 142/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2652 - val_loss: 0.1815\n",
            "Epoch 143/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2640 - val_loss: 0.1793\n",
            "Epoch 144/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2630 - val_loss: 0.1815\n",
            "Epoch 145/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2627 - val_loss: 0.1819\n",
            "Epoch 146/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2619 - val_loss: 0.1789\n",
            "Epoch 147/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2596 - val_loss: 0.1824\n",
            "Epoch 148/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2593 - val_loss: 0.1814\n",
            "Epoch 149/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2586 - val_loss: 0.1798\n",
            "Epoch 150/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2579 - val_loss: 0.1808\n",
            "Epoch 151/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2568 - val_loss: 0.1798\n",
            "Epoch 152/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2563 - val_loss: 0.1828\n",
            "Epoch 153/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2558 - val_loss: 0.1780\n",
            "Epoch 154/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2538 - val_loss: 0.1845\n",
            "Epoch 155/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2539 - val_loss: 0.1796\n",
            "Epoch 156/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2531 - val_loss: 0.1838\n",
            "Epoch 157/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2541 - val_loss: 0.1797\n",
            "Epoch 158/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2525 - val_loss: 0.1830\n",
            "Epoch 159/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2507 - val_loss: 0.1807\n",
            "Epoch 160/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2495 - val_loss: 0.1800\n",
            "Epoch 161/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2493 - val_loss: 0.1776\n",
            "Epoch 162/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2482 - val_loss: 0.1808\n",
            "Epoch 163/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2473 - val_loss: 0.1815\n",
            "Epoch 164/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2469 - val_loss: 0.1791\n",
            "Epoch 165/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2459 - val_loss: 0.1829\n",
            "Epoch 166/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2460 - val_loss: 0.1800\n",
            "Epoch 167/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2456 - val_loss: 0.1832\n",
            "Epoch 168/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2438 - val_loss: 0.1778\n",
            "Epoch 169/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2447 - val_loss: 0.1809\n",
            "Epoch 170/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2444 - val_loss: 0.1821\n",
            "Epoch 171/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2430 - val_loss: 0.1818\n",
            "Epoch 172/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2414 - val_loss: 0.1797\n",
            "Epoch 173/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2407 - val_loss: 0.1831\n",
            "Epoch 174/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2410 - val_loss: 0.1805\n",
            "Epoch 175/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2395 - val_loss: 0.1798\n",
            "Epoch 176/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2396 - val_loss: 0.1838\n",
            "Epoch 177/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2388 - val_loss: 0.1812\n",
            "Epoch 178/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2371 - val_loss: 0.1785\n",
            "Epoch 179/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2366 - val_loss: 0.1818\n",
            "Epoch 180/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2389 - val_loss: 0.1813\n",
            "Epoch 181/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2363 - val_loss: 0.1795\n",
            "Epoch 182/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2349 - val_loss: 0.1869\n",
            "Epoch 183/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2350 - val_loss: 0.1798\n",
            "Epoch 184/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2348 - val_loss: 0.1841\n",
            "Epoch 185/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2328 - val_loss: 0.1789\n",
            "Epoch 186/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2344 - val_loss: 0.1794\n",
            "Epoch 187/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2334 - val_loss: 0.1805\n",
            "Epoch 188/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2311 - val_loss: 0.1823\n",
            "Epoch 189/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2337 - val_loss: 0.1808\n",
            "Epoch 190/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2312 - val_loss: 0.1804\n",
            "Epoch 191/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2311 - val_loss: 0.1792\n",
            "Epoch 192/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2299 - val_loss: 0.1814\n",
            "Epoch 193/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2294 - val_loss: 0.1824\n",
            "Epoch 194/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2290 - val_loss: 0.1802\n",
            "Epoch 195/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2280 - val_loss: 0.1814\n",
            "Epoch 196/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2270 - val_loss: 0.1836\n",
            "Epoch 197/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2276 - val_loss: 0.1804\n",
            "Epoch 198/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2262 - val_loss: 0.1830\n",
            "Epoch 199/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2264 - val_loss: 0.1802\n",
            "Epoch 200/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2278 - val_loss: 0.1882\n",
            "Epoch 201/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2248 - val_loss: 0.1808\n",
            "Epoch 202/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2255 - val_loss: 0.1795\n",
            "Epoch 203/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2237 - val_loss: 0.1850\n",
            "Epoch 204/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2234 - val_loss: 0.1840\n",
            "Epoch 205/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2251 - val_loss: 0.1882\n",
            "Epoch 206/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2237 - val_loss: 0.1796\n",
            "Epoch 207/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2229 - val_loss: 0.1844\n",
            "Epoch 208/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2221 - val_loss: 0.1813\n",
            "Epoch 209/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2210 - val_loss: 0.1795\n",
            "Epoch 210/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2213 - val_loss: 0.1831\n",
            "Epoch 211/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2200 - val_loss: 0.1791\n",
            "Epoch 212/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2199 - val_loss: 0.1808\n",
            "Epoch 213/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2204 - val_loss: 0.1821\n",
            "Epoch 214/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2214 - val_loss: 0.1826\n",
            "Epoch 215/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2189 - val_loss: 0.1852\n",
            "Epoch 216/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2186 - val_loss: 0.1812\n",
            "Epoch 217/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2189 - val_loss: 0.1878\n",
            "Epoch 218/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2266 - val_loss: 0.1798\n",
            "Epoch 219/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2216 - val_loss: 0.1908\n",
            "Epoch 220/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2170 - val_loss: 0.1844\n",
            "Epoch 221/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2164 - val_loss: 0.1835\n",
            "Epoch 222/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2153 - val_loss: 0.1810\n",
            "Epoch 223/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2155 - val_loss: 0.1826\n",
            "Epoch 224/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2158 - val_loss: 0.1850\n",
            "Epoch 225/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2168 - val_loss: 0.1820\n",
            "Epoch 226/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2151 - val_loss: 0.1826\n",
            "Epoch 227/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2134 - val_loss: 0.1843\n",
            "Epoch 228/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2140 - val_loss: 0.1828\n",
            "Epoch 229/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2134 - val_loss: 0.1848\n",
            "Epoch 230/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2136 - val_loss: 0.1831\n",
            "Epoch 231/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2123 - val_loss: 0.1829\n",
            "Epoch 232/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2121 - val_loss: 0.1845\n",
            "Epoch 233/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2121 - val_loss: 0.1827\n",
            "Epoch 234/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2111 - val_loss: 0.1814\n",
            "Epoch 235/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2116 - val_loss: 0.1852\n",
            "Epoch 236/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2107 - val_loss: 0.1805\n",
            "Epoch 237/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2107 - val_loss: 0.1837\n",
            "Epoch 238/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2097 - val_loss: 0.1838\n",
            "Epoch 239/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2101 - val_loss: 0.1900\n",
            "Epoch 240/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2092 - val_loss: 0.1836\n",
            "Epoch 241/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2091 - val_loss: 0.1863\n",
            "Epoch 242/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2097 - val_loss: 0.1859\n",
            "Epoch 243/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2087 - val_loss: 0.1862\n",
            "Epoch 244/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2089 - val_loss: 0.1842\n",
            "Epoch 245/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2102 - val_loss: 0.1868\n",
            "Epoch 246/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2090 - val_loss: 0.1886\n",
            "Epoch 247/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2072 - val_loss: 0.1824\n",
            "Epoch 248/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2066 - val_loss: 0.1868\n",
            "Epoch 249/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2070 - val_loss: 0.1853\n",
            "Epoch 250/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2071 - val_loss: 0.1865\n",
            "Epoch 251/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2072 - val_loss: 0.1856\n",
            "Epoch 252/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2070 - val_loss: 0.1833\n",
            "Epoch 253/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2047 - val_loss: 0.1856\n",
            "Epoch 254/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2060 - val_loss: 0.1873\n",
            "Epoch 255/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2065 - val_loss: 0.1812\n",
            "Epoch 256/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2062 - val_loss: 0.1875\n",
            "Epoch 257/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2052 - val_loss: 0.1840\n",
            "Epoch 258/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2073 - val_loss: 0.1918\n",
            "Epoch 259/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2036 - val_loss: 0.1840\n",
            "Epoch 260/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2038 - val_loss: 0.1881\n",
            "Epoch 261/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2038 - val_loss: 0.1893\n",
            "Epoch 262/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2044 - val_loss: 0.1902\n",
            "Epoch 263/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2020 - val_loss: 0.1841\n",
            "Epoch 264/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2051 - val_loss: 0.1891\n",
            "Epoch 265/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2014 - val_loss: 0.1812\n",
            "Epoch 266/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2021 - val_loss: 0.1880\n",
            "Epoch 267/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2014 - val_loss: 0.1839\n",
            "Epoch 268/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2011 - val_loss: 0.1877\n",
            "Epoch 269/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2015 - val_loss: 0.1904\n",
            "Epoch 270/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2031 - val_loss: 0.1842\n",
            "Epoch 271/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2030 - val_loss: 0.1912\n",
            "Epoch 272/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2067 - val_loss: 0.1821\n",
            "Epoch 273/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2023 - val_loss: 0.1868\n",
            "Epoch 274/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1994 - val_loss: 0.1854\n",
            "Epoch 275/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.2002 - val_loss: 0.1858\n",
            "Epoch 276/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2026 - val_loss: 0.1898\n",
            "Epoch 277/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2055 - val_loss: 0.1830\n",
            "Epoch 278/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2040 - val_loss: 0.1891\n",
            "Epoch 279/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1980 - val_loss: 0.1853\n",
            "Epoch 280/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1974 - val_loss: 0.1865\n",
            "Epoch 281/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1986 - val_loss: 0.1885\n",
            "Epoch 282/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1989 - val_loss: 0.1875\n",
            "Epoch 283/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1974 - val_loss: 0.1844\n",
            "Epoch 284/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1971 - val_loss: 0.1853\n",
            "Epoch 285/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1974 - val_loss: 0.1854\n",
            "Epoch 286/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1977 - val_loss: 0.1894\n",
            "Epoch 287/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1974 - val_loss: 0.1868\n",
            "Epoch 288/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1972 - val_loss: 0.1849\n",
            "Epoch 289/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1950 - val_loss: 0.1909\n",
            "Epoch 290/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1965 - val_loss: 0.1933\n",
            "Epoch 291/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1958 - val_loss: 0.1902\n",
            "Epoch 292/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1963 - val_loss: 0.1830\n",
            "Epoch 293/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1949 - val_loss: 0.1877\n",
            "Epoch 294/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1951 - val_loss: 0.1866\n",
            "Epoch 295/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1950 - val_loss: 0.1896\n",
            "Epoch 296/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2018 - val_loss: 0.1969\n",
            "Epoch 297/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1970 - val_loss: 0.1896\n",
            "Epoch 298/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1943 - val_loss: 0.1903\n",
            "Epoch 299/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1933 - val_loss: 0.1933\n",
            "Epoch 300/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1953 - val_loss: 0.1871\n",
            "Epoch 301/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1950 - val_loss: 0.1912\n",
            "Epoch 302/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1960 - val_loss: 0.1939\n",
            "Epoch 303/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1947 - val_loss: 0.1915\n",
            "Epoch 304/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1937 - val_loss: 0.1916\n",
            "Epoch 305/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1949 - val_loss: 0.1899\n",
            "Epoch 306/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1932 - val_loss: 0.1946\n",
            "Epoch 307/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1935 - val_loss: 0.1836\n",
            "Epoch 308/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1954 - val_loss: 0.1940\n",
            "Epoch 309/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2011 - val_loss: 0.1933\n",
            "Epoch 310/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1977 - val_loss: 0.1897\n",
            "Epoch 311/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1927 - val_loss: 0.1930\n",
            "Epoch 312/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1957 - val_loss: 0.1912\n",
            "Epoch 313/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1925 - val_loss: 0.1878\n",
            "Epoch 314/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1909 - val_loss: 0.1915\n",
            "Epoch 315/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1900 - val_loss: 0.1916\n",
            "Epoch 316/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1906 - val_loss: 0.1869\n",
            "Epoch 317/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1914 - val_loss: 0.1959\n",
            "Epoch 318/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1906 - val_loss: 0.1903\n",
            "Epoch 319/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1913 - val_loss: 0.1863\n",
            "Epoch 320/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1901 - val_loss: 0.1905\n",
            "Epoch 321/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1898 - val_loss: 0.1935\n",
            "Epoch 322/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1899 - val_loss: 0.1897\n",
            "Epoch 323/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1892 - val_loss: 0.1894\n",
            "Epoch 324/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1900 - val_loss: 0.1918\n",
            "Epoch 325/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1888 - val_loss: 0.1889\n",
            "Epoch 326/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1919 - val_loss: 0.2001\n",
            "Epoch 327/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1910 - val_loss: 0.1971\n",
            "Epoch 328/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1899 - val_loss: 0.1887\n",
            "Epoch 329/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1894 - val_loss: 0.1963\n",
            "Epoch 330/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1881 - val_loss: 0.1922\n",
            "Epoch 331/500\n",
            "19/19 [==============================] - 0s 20ms/step - loss: 0.1880 - val_loss: 0.1921\n",
            "Epoch 332/500\n",
            "19/19 [==============================] - 0s 22ms/step - loss: 0.1876 - val_loss: 0.1933\n",
            "Epoch 333/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.1882 - val_loss: 0.1966\n",
            "Epoch 334/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1891 - val_loss: 0.1907\n",
            "Epoch 335/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1892 - val_loss: 0.1909\n",
            "Epoch 336/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1900 - val_loss: 0.1931\n",
            "Epoch 337/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1899 - val_loss: 0.1910\n",
            "Epoch 338/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1899 - val_loss: 0.1919\n",
            "Epoch 339/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1883 - val_loss: 0.1898\n",
            "Epoch 340/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1871 - val_loss: 0.1977\n",
            "Epoch 341/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1871 - val_loss: 0.1910\n",
            "Epoch 342/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1886 - val_loss: 0.1957\n",
            "Epoch 343/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1883 - val_loss: 0.1936\n",
            "Epoch 344/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1904 - val_loss: 0.1923\n",
            "Epoch 345/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1894 - val_loss: 0.1877\n",
            "Epoch 346/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1895 - val_loss: 0.1937\n",
            "Epoch 347/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1853 - val_loss: 0.1886\n",
            "Epoch 348/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1874 - val_loss: 0.1892\n",
            "Epoch 349/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1848 - val_loss: 0.1984\n",
            "Epoch 350/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1866 - val_loss: 0.1875\n",
            "Epoch 351/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1857 - val_loss: 0.2023\n",
            "Epoch 352/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1864 - val_loss: 0.1914\n",
            "Epoch 353/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1872 - val_loss: 0.1983\n",
            "Epoch 354/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1871 - val_loss: 0.1891\n",
            "Epoch 355/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1885 - val_loss: 0.1938\n",
            "Epoch 356/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1864 - val_loss: 0.1941\n",
            "Epoch 357/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1870 - val_loss: 0.1959\n",
            "Epoch 358/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1885 - val_loss: 0.1963\n",
            "Epoch 359/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1885 - val_loss: 0.1954\n",
            "Epoch 360/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2039 - val_loss: 0.1910\n",
            "Epoch 361/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1893 - val_loss: 0.1946\n",
            "Epoch 362/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1845 - val_loss: 0.1923\n",
            "Epoch 363/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1834 - val_loss: 0.1978\n",
            "Epoch 364/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1848 - val_loss: 0.1958\n",
            "Epoch 365/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1838 - val_loss: 0.1917\n",
            "Epoch 366/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1839 - val_loss: 0.1920\n",
            "Epoch 367/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1828 - val_loss: 0.1962\n",
            "Epoch 368/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1820 - val_loss: 0.1951\n",
            "Epoch 369/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1834 - val_loss: 0.1995\n",
            "Epoch 370/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1819 - val_loss: 0.1955\n",
            "Epoch 371/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1828 - val_loss: 0.1963\n",
            "Epoch 372/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1827 - val_loss: 0.2013\n",
            "Epoch 373/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1827 - val_loss: 0.1954\n",
            "Epoch 374/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1853 - val_loss: 0.1920\n",
            "Epoch 375/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1845 - val_loss: 0.2013\n",
            "Epoch 376/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1825 - val_loss: 0.1952\n",
            "Epoch 377/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1847 - val_loss: 0.1946\n",
            "Epoch 378/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2109 - val_loss: 0.1915\n",
            "Epoch 379/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1886 - val_loss: 0.1952\n",
            "Epoch 380/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1828 - val_loss: 0.1980\n",
            "Epoch 381/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1817 - val_loss: 0.1945\n",
            "Epoch 382/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1805 - val_loss: 0.1965\n",
            "Epoch 383/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1807 - val_loss: 0.1962\n",
            "Epoch 384/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1823 - val_loss: 0.1927\n",
            "Epoch 385/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1810 - val_loss: 0.1990\n",
            "Epoch 386/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1865 - val_loss: 0.1929\n",
            "Epoch 387/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1838 - val_loss: 0.1933\n",
            "Epoch 388/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1824 - val_loss: 0.1990\n",
            "Epoch 389/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1810 - val_loss: 0.1935\n",
            "Epoch 390/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1802 - val_loss: 0.1947\n",
            "Epoch 391/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1805 - val_loss: 0.2030\n",
            "Epoch 392/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1808 - val_loss: 0.1991\n",
            "Epoch 393/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1807 - val_loss: 0.2040\n",
            "Epoch 394/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1797 - val_loss: 0.1957\n",
            "Epoch 395/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1853 - val_loss: 0.2078\n",
            "Epoch 396/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1793 - val_loss: 0.1969\n",
            "Epoch 397/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1792 - val_loss: 0.2119\n",
            "Epoch 398/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1811 - val_loss: 0.1994\n",
            "Epoch 399/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1805 - val_loss: 0.1989\n",
            "Epoch 400/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1817 - val_loss: 0.1935\n",
            "Epoch 401/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1857 - val_loss: 0.2111\n",
            "Epoch 402/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1793 - val_loss: 0.1968\n",
            "Epoch 403/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1798 - val_loss: 0.1963\n",
            "Epoch 404/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1798 - val_loss: 0.2017\n",
            "Epoch 405/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1787 - val_loss: 0.1938\n",
            "Epoch 406/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1802 - val_loss: 0.2010\n",
            "Epoch 407/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1803 - val_loss: 0.2056\n",
            "Epoch 408/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1798 - val_loss: 0.1972\n",
            "Epoch 409/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1782 - val_loss: 0.2028\n",
            "Epoch 410/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1782 - val_loss: 0.1955\n",
            "Epoch 411/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1789 - val_loss: 0.1993\n",
            "Epoch 412/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1780 - val_loss: 0.2026\n",
            "Epoch 413/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1777 - val_loss: 0.2043\n",
            "Epoch 414/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1777 - val_loss: 0.1982\n",
            "Epoch 415/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1770 - val_loss: 0.1982\n",
            "Epoch 416/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.1781 - val_loss: 0.2060\n",
            "Epoch 417/500\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.1762 - val_loss: 0.2004\n",
            "Epoch 418/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1801 - val_loss: 0.1983\n",
            "Epoch 419/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1791 - val_loss: 0.2118\n",
            "Epoch 420/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1778 - val_loss: 0.1995\n",
            "Epoch 421/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1763 - val_loss: 0.2044\n",
            "Epoch 422/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1770 - val_loss: 0.1994\n",
            "Epoch 423/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1763 - val_loss: 0.1979\n",
            "Epoch 424/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1798 - val_loss: 0.2136\n",
            "Epoch 425/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1786 - val_loss: 0.2008\n",
            "Epoch 426/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1790 - val_loss: 0.1994\n",
            "Epoch 427/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1786 - val_loss: 0.1946\n",
            "Epoch 428/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1767 - val_loss: 0.2107\n",
            "Epoch 429/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1842 - val_loss: 0.1942\n",
            "Epoch 430/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1814 - val_loss: 0.2075\n",
            "Epoch 431/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1810 - val_loss: 0.2038\n",
            "Epoch 432/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1796 - val_loss: 0.2017\n",
            "Epoch 433/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1759 - val_loss: 0.2057\n",
            "Epoch 434/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1772 - val_loss: 0.2120\n",
            "Epoch 435/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1776 - val_loss: 0.2058\n",
            "Epoch 436/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1809 - val_loss: 0.1955\n",
            "Epoch 437/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1770 - val_loss: 0.2016\n",
            "Epoch 438/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1784 - val_loss: 0.2006\n",
            "Epoch 439/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1793 - val_loss: 0.2015\n",
            "Epoch 440/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1819 - val_loss: 0.2033\n",
            "Epoch 441/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1798 - val_loss: 0.2075\n",
            "Epoch 442/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1837 - val_loss: 0.2031\n",
            "Epoch 443/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1825 - val_loss: 0.2176\n",
            "Epoch 444/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1787 - val_loss: 0.2060\n",
            "Epoch 445/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1797 - val_loss: 0.2039\n",
            "Epoch 446/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1843 - val_loss: 0.2086\n",
            "Epoch 447/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1881 - val_loss: 0.2009\n",
            "Epoch 448/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1915 - val_loss: 0.2137\n",
            "Epoch 449/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1953 - val_loss: 0.1993\n",
            "Epoch 450/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1866 - val_loss: 0.2065\n",
            "Epoch 451/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1800 - val_loss: 0.2013\n",
            "Epoch 452/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1769 - val_loss: 0.2036\n",
            "Epoch 453/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1754 - val_loss: 0.2024\n",
            "Epoch 454/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1760 - val_loss: 0.2061\n",
            "Epoch 455/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1743 - val_loss: 0.2004\n",
            "Epoch 456/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1736 - val_loss: 0.2035\n",
            "Epoch 457/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1735 - val_loss: 0.2087\n",
            "Epoch 458/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1736 - val_loss: 0.1989\n",
            "Epoch 459/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1738 - val_loss: 0.2128\n",
            "Epoch 460/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1757 - val_loss: 0.2037\n",
            "Epoch 461/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1738 - val_loss: 0.2080\n",
            "Epoch 462/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1742 - val_loss: 0.2023\n",
            "Epoch 463/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1743 - val_loss: 0.2035\n",
            "Epoch 464/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1730 - val_loss: 0.2063\n",
            "Epoch 465/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.1744 - val_loss: 0.2013\n",
            "Epoch 466/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.1736 - val_loss: 0.2018\n",
            "Epoch 467/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.1746 - val_loss: 0.2017\n",
            "Epoch 468/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.1775 - val_loss: 0.2068\n",
            "Epoch 469/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1764 - val_loss: 0.2026\n",
            "Epoch 470/500\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.1741 - val_loss: 0.2104\n",
            "Epoch 471/500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.1768 - val_loss: 0.2057\n",
            "Epoch 472/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1789 - val_loss: 0.2107\n",
            "Epoch 473/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1734 - val_loss: 0.2063\n",
            "Epoch 474/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1741 - val_loss: 0.2049\n",
            "Epoch 475/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1765 - val_loss: 0.2167\n",
            "Epoch 476/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1729 - val_loss: 0.2051\n",
            "Epoch 477/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1721 - val_loss: 0.2087\n",
            "Epoch 478/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1736 - val_loss: 0.2150\n",
            "Epoch 479/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1728 - val_loss: 0.2059\n",
            "Epoch 480/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1722 - val_loss: 0.2031\n",
            "Epoch 481/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1723 - val_loss: 0.2120\n",
            "Epoch 482/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1717 - val_loss: 0.2070\n",
            "Epoch 483/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1720 - val_loss: 0.2098\n",
            "Epoch 484/500\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.1726 - val_loss: 0.2096\n",
            "Epoch 485/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1720 - val_loss: 0.2040\n",
            "Epoch 486/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1720 - val_loss: 0.2137\n",
            "Epoch 487/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1726 - val_loss: 0.2041\n",
            "Epoch 488/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1734 - val_loss: 0.2016\n",
            "Epoch 489/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1758 - val_loss: 0.2022\n",
            "Epoch 490/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1737 - val_loss: 0.2069\n",
            "Epoch 491/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1717 - val_loss: 0.2073\n",
            "Epoch 492/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1732 - val_loss: 0.2142\n",
            "Epoch 493/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1729 - val_loss: 0.2070\n",
            "Epoch 494/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1734 - val_loss: 0.2018\n",
            "Epoch 495/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1715 - val_loss: 0.2071\n",
            "Epoch 496/500\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.1712 - val_loss: 0.2108\n",
            "Epoch 497/500\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.1710 - val_loss: 0.2141\n",
            "Epoch 498/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1707 - val_loss: 0.2006\n",
            "Epoch 499/500\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.1714 - val_loss: 0.2047\n",
            "Epoch 500/500\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.1719 - val_loss: 0.2122\n"
          ]
        }
      ],
      "source": [
        "from keras.optimizers.schedules.learning_rate_schedule import LearningRateSchedule\n",
        "\n",
        "epoch = 500\n",
        "batch = 64\n",
        "reset_seeds()\n",
        "\n",
        "history = house.fit(Xtrain_selected, \n",
        "                    ytrain_encoded, \n",
        "                    batch_size = batch, \n",
        "                    epochs = epoch, \n",
        "                    validation_data = (Xval_selected, yval_encoded))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LgO6NAXQ_9OJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "def compute_rmsle(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
        "  rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
        "  return round(rmsle, precision)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Machine Learning model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = gbr_model.predict(Xtest_encoded)\n",
        "y_pred = y_pred.reshape(len(y_pred), 1)\n",
        "\n",
        "y_hat = std_label.inverse_transform(y_pred).flatten()\n",
        "ytest_true =ytest['SalePrice'].values.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.14"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rmse = compute_rmsle(ytest_true, y_hat)\n",
        "rmse"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Neural Network model evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Let's plot the loss of the model from training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "tu3z_8Ne_RsJ",
        "outputId": "9725beea-2cee-4ff9-c95f-ae40346a8116"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss, val_loss = history.history['loss'], history.history['val_loss']\n",
        "plt.plot(loss, label=\"Training Loss\")\n",
        "plt.plot(val_loss, label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Let's evaluate the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mZVi2eUGIYY",
        "outputId": "b00118aa-2fc1-434d-cca5-bc3e570efe38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = house.predict(Xtest_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "GARozYVkGQgw"
      },
      "outputs": [],
      "source": [
        "y_hat = std_label.inverse_transform(y_pred)\n",
        "\n",
        "ytest_true = ytest['SalePrice'].values\n",
        "ytrain_true =ytrain['SalePrice'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs-gOzIiGq5Q",
        "outputId": "5993b3a7-f474-408b-e9dd-75beb505c934"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.21"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = compute_rmsle(ytest_true, y_hat)\n",
        "results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Discussion\n",
        "The RMSE I got from neural network model is not very good. The best value I got from training is 0.18 with different parameter setup of the model and feature selection. There might be a better way to model the relationship between the features and the target variable, or I can improve the performance of the model by using a different feature projection method."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The machine learning approach with gradient boosting is a simpler and better solution than the neural network approach for this task. It could be due to the fact that we have a very small number of samples whereas the neural network approach often requires a large number of samples to learn as there are more parameters that need to be tuned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
